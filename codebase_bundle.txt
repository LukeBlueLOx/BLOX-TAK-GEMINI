Project Bundle: /home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI
========================================

--- START FILE: prompts.txt ---
        base_prompt = (
            f"Jesteś ekspertem prawnym - zacytuj i potem wyjaśnij mi wskazane artykuły z Polskiego KPC, "
            f"a także jakie prawa mi przysługują w związku z tym. Opisz to w języku Polskim i następnie dodaj także "
            f"tłumaczenie w języku Angielskim. Podaj również na końcu treść użytego promptu - analogicznie w języku "
            f"Polskim i Angielskim, a także wersję modelu jaki został użyty - czyli: gemini-1.5-flash,"
            f"z pełnym timestamp: " + full_timestamp
        )

        base_prompt = (
            f"Jesteś ekspertem prawnym - przeanalizuj dokument pod kątem Prawa Polskiego i Uni Europejskiej."
            f"Zacytuj artykuły i opisz jakie moje prawa zostały złamane"
            f"Wynik podaj w języku Polskim i Angielskim. Podaj również na końcu treść użytego promptu - analogicznie w języku "
            f"Polskim i Angielskim, a także wersję modelu jaki został użyty - czyli: gemini-1.5-flash,"
            f"z pełnym timestamp: " + full_timestamp
        )



        base_overall_prompt = (
        #f"Jesteś ekspertem prawnym. Otrzymujesz serię analiz prawnych (lub ich fragmentów), "
        #f"które dotyczą różnych przypadków naruszenia praw i wolności obywatelskich w świetle Konstytucji RP. "
        #f"Twoim zadaniem jest stworzenie JEDNEGO, SPÓJNEGO podsumowania wszystkich tych analiz. "
        #f"Skup się na: "
        #f"1. **Głównych kategoriach naruszeń Konstytucji RP**, które powtarzają się w analizach. "
        #f"2. **Wzorcach lub schematach działania**, jeśli takie występują w opisanych przypadkach. "
        #f"3. **Najczęściej naruszanych artykułach Konstytucji RP** (bez enumerowania każdego artykułu z osobna, ale wskazanie dominujących obszarów). "
        #f"4. **Ogólnych wnioskach** dotyczących natury problemów prawnych. "
        #f"Nie powtarzaj szczegółów konkretnych przypadków, chyba że są kluczowe dla zilustrowania wzorca. "
        #f"Podsumowanie powinno być zwięzłe, syntetyczne i skupione na ogólnym obrazie sytuacji prawnej. "
        #f"Pomiń wszelkie wstępy i zakończenia, skup się na meritum podsumowania."
    )
--- END FILE: prompts.txt ---

--- START FILE: requirements.txt ---
aiofiles==24.1.0
aiohappyeyeballs==2.6.1
aiohttp==3.12.13
aiosignal==1.3.2
annotated-types==0.7.0
anyio==4.9.0
asttokens==3.0.0
async-timeout==4.0.3
attrs==25.3.0
backcall==0.2.0
backoff==2.2.1
bcrypt==4.3.0
beautifulsoup4==4.13.4
bleach==6.2.0
build==1.2.2.post1
cachetools==5.5.2
certifi==2025.4.26
cffi==1.17.1
chardet==5.2.0
charset-normalizer==3.4.2
chromadb==1.0.13
click==8.2.1
coloredlogs==15.0.1
cryptography==43.0.3
dataclasses-json==0.6.7
decorator==5.2.1
defusedxml==0.7.1
distro==1.9.0
docopt==0.6.2
durationpy==0.10
emoji==2.14.1
exceptiongroup==1.3.0
executing==2.2.0
fastjsonschema==2.21.1
filelock==3.18.0
filetype==1.2.0
flatbuffers==25.2.10
frozenlist==1.7.0
fsspec==2025.5.1
generativeai==0.0.1
google-ai-generativelanguage==0.6.18
google-api-core==2.25.1
google-api-python-client==2.172.0
google-auth==2.40.3
google-auth-httplib2==0.2.0
google-generativeai==0.8.5
googleapis-common-protos==1.70.0
greenlet==3.2.3
grpcio==1.73.0
grpcio-status==1.71.0
h11==0.16.0
hf-xet==1.1.3
html5lib==1.1
httpcore==1.0.9
httplib2==0.22.0
httptools==0.6.4
httpx==0.28.1
httpx-sse==0.4.0
huggingface-hub==0.33.0
humanfriendly==10.0
idna==3.10
importlib_metadata==8.7.0
importlib_resources==6.5.2
ipython==8.12.3
jedi==0.19.2
Jinja2==3.1.6
joblib==1.5.1
jsonpatch==1.33
jsonpointer==3.0.0
jsonschema==4.24.0
jsonschema-specifications==2025.4.1
jupyter_client==8.6.3
jupyter_core==5.8.1
jupyterlab_pygments==0.3.0
kubernetes==33.1.0
langchain==0.3.25
langchain-chroma==0.2.4
langchain-community==0.3.25
langchain-core==0.3.65
langchain-google-genai==2.1.5
langchain-text-splitters==0.3.8
langdetect==1.0.9
langsmith==0.3.45
lxml==5.4.0
markdown-it-py==3.0.0
MarkupSafe==3.0.2
marshmallow==3.26.1
matplotlib-inline==0.1.7
mdurl==0.1.2
mistune==3.1.3
mmh3==5.1.0
mpmath==1.3.0
multidict==6.5.0
mypy_extensions==1.1.0
nbclient==0.10.2
nbconvert==7.16.6
nbformat==5.10.4
nest-asyncio==1.6.0
nltk==3.9.1
numpy==2.2.6
oauth2client==4.1.3
oauthlib==3.3.1
olefile==0.47
onnxruntime==1.22.0
opentelemetry-api==1.34.1
opentelemetry-exporter-otlp-proto-common==1.34.1
opentelemetry-exporter-otlp-proto-grpc==1.34.1
opentelemetry-proto==1.34.1
opentelemetry-sdk==1.34.1
opentelemetry-semantic-conventions==0.55b1
orjson==3.10.18
overrides==7.7.0
packaging==24.2
pandocfilters==1.5.1
parso==0.8.4
pdfminer.six==20250506
pdfplumber==0.11.7
pexpect==4.9.0
pickleshare==0.7.5
pillow==11.2.1
pipreqs==0.5.0
platformdirs==4.3.8
posthog==5.3.0
prompt_toolkit==3.0.51
propcache==0.3.2
proto-plus==1.26.1
protobuf==5.29.5
psutil==7.0.0
ptyprocess==0.7.0
pure_eval==0.2.3
py==1.4.22
pyasn1==0.6.1
pyasn1_modules==0.4.2
pybase64==1.4.1
pycparser==2.22
pydantic==2.11.6
pydantic-settings==2.9.1
pydantic_core==2.33.2
PyDrive2==1.21.3
Pygments==2.19.1
pyOpenSSL==24.2.1
pyparsing==3.2.3
pypdf==5.6.0
pypdfium2==4.30.1
PyPika==0.48.9
pyproject_hooks==1.2.0
pytest==2.6.0
python-dateutil==2.9.0.post0
python-dotenv==1.1.0
python-iso639==2025.2.18
python-magic==0.4.27
python-oxmsg==0.0.2
PyYAML==6.0.2
pyzmq==26.4.0
RapidFuzz==3.13.0
referencing==0.36.2
regex==2024.11.6
reportlab==4.4.1
requests==2.32.4
requests-oauthlib==2.0.0
requests-toolbelt==1.0.0
rich==14.0.0
rpds-py==0.25.1
rsa==4.9.1
shellingham==1.5.4
six==1.17.0
sniffio==1.3.1
soupsieve==2.7
SQLAlchemy==2.0.41
stack-data==0.6.3
sympy==1.14.0
tenacity==9.1.2
tinycss2==1.4.0
tokenizers==0.21.1
tomli==2.2.1
tornado==6.5.1
tqdm==4.67.1
traitlets==5.14.3
typer==0.16.0
typing-inspect==0.9.0
typing-inspection==0.4.1
typing_extensions==4.14.0
uno==0.3.3
unstructured==0.17.2
unstructured-client==0.36.0
uritemplate==4.2.0
urllib3==2.4.0
uvicorn==0.34.3
uvloop==0.21.0
watchfiles==1.1.0
wcwidth==0.2.13
webencodings==0.5.1
websocket-client==1.8.0
websockets==15.0.1
wrapt==1.17.2
yarg==0.1.9
yarl==1.20.1
zipp==3.23.0
zstandard==0.23.0

--- END FILE: requirements.txt ---

--- START FILE: README.md ---
<hr>

<div align="center"> 

### BLOX-TAK-GEMINI

</div> 

<hr>

<div align="center">

### ✌️🦅🇺🇸🇪🇺🇵🇱🇪🇺🇺🇸🦅✌️

https://www.linkedin.com/posts/lukebluelox_blox-tak-gemini-activity-7337727514405957632-m6BQ

https://www.linkedin.com/posts/lukebluelox_blox-tak-gemini-activity-7340991837509189632-7j_N

Gemini 2.5 PRO Generated Image (2K25Y)
<img src="Gemini_Generated_Image_qybg50qybg50qybg.jpeg" width="" height=""/>
<br>

Real-Oryginal Image (2K16Y)
<img src="Real-Oryginal.jpg" width="" height=""/>


<img src="BLOX-TAK_SF_WP.png" width="" height=""/>
<br>

<img src="1.png" width="" height=""/>
<br>

<img src="2.png" width="" height=""/>
<br>

<img src="3.png" width="" height=""/>
<br>

<img src="4.png" width="" height=""/>
<br>

<img src="5.png" width="" height=""/>

### ✌♻️🌌🚀🌎🌍🌏🛰🌌♻️✌

https://en.wikipedia.org/wiki/Gemini_(language_model)

https://en.wikipedia.org/wiki/Nvidia

</div>

<hr>

--- END FILE: README.md ---

--- START FILE: KNOWLEDGE_BASE/VECTOR_DB_LEGAL/initial.txt ---

--- END FILE: KNOWLEDGE_BASE/VECTOR_DB_LEGAL/initial.txt ---

--- START FILE: KNOWLEDGE_BASE/VECTOR_DB_CASE/initial.txt ---

--- END FILE: KNOWLEDGE_BASE/VECTOR_DB_CASE/initial.txt ---

--- START FILE: RAG/rag_query_assistant_test1.py ---
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# --- Standard Python Libraries ---
# --- Standardowe Biblioteki Pythona ---

# For filesystem operations like creating paths.
# Do operacji na systemie plików, np. tworzenia ścieżek.
import os

# For loading configuration from YAML files.
# Do wczytywania konfiguracji z plików YAML.
import yaml

# For high-level file operations like deleting directory trees.
# Do operacji na plikach wysokiego poziomu, jak usuwanie drzew katalogów.
import shutil

# For creating and managing logs (to console and file).
# Do tworzenia i zarządzania logami (do konsoli i pliku).
import logging
from logging.handlers import RotatingFileHandler

# --- LangChain & Google Libraries ---
# --- Biblioteki LangChain i Google ---

# LangChain's specific integrations for Google's Generative AI models (LLM and Embeddings).
# Specyficzne integracje LangChain dla modeli Generative AI od Google (LLM i Embeddings).
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings

# LangChain's integration for the Chroma vector database.
# Integracja LangChain dla wektorowej bazy danych Chroma.
from langchain_chroma import Chroma

# A tool for creating reusable and structured prompts for the language model.
# Narzędzie do tworzenia reużywalnych i ustrukturyzowanych promptów dla modelu językowego.
from langchain.prompts import PromptTemplate

# A core component of LangChain Expression Language (LCEL) to pass inputs through the chain.
# Kluczowy komponent Języka Wyrażeń LangChain (LCEL) do przekazywania danych wejściowych w łańcuchu.
from langchain.schema.runnable import RunnablePassthrough

# A simple parser to convert the language model's output into a standard string.
# Prosty parser do konwersji wyniku modelu językowego na standardowy ciąg znaków.
from langchain.schema.output_parser import StrOutputParser

# --- Local Project Modules ---
# --- Lokalne Moduły Projektu ---

# Importing our custom function from the preprocessor script to get prepared documents.
# Importowanie naszej własnej funkcji ze skryptu preprocesora, aby pobrać przygotowane dokumenty.
from RAG.rag_data_preprocessor import get_documents_from_source


def setup_logger(log_folder: str):
    """
    Sets up a logger to output to both console and a rotating file.
    Konfiguruje logger do zapisu zarówno do konsoli, jak i do rotacyjnego pliku.
    """
    if not os.path.exists(log_folder):
        os.makedirs(log_folder)

    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    if logger.hasHandlers():
        logger.handlers.clear()

    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    fh = RotatingFileHandler(os.path.join(log_folder, 'rag_assistant.log'), maxBytes=5 * 1024 * 1024, backupCount=3)
    fh.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    fh.setFormatter(formatter)
    logger.addHandler(ch)
    logger.addHandler(fh)
    return logger


def load_configuration(config_path="scripts/config.yaml"):
    """
    Loads the main configuration file.
    Wczytuje główny plik konfiguracyjny.
    """
    try:
        with open(config_path, "r", encoding="utf-8") as cr:
            config = yaml.full_load(cr)

        base_path = config['base_path']
        rag_config = config['rag_pipeline_config']

        conf = {
            "GOOGLE_API_KEY": config['KEY'],
            "LEGAL_SOURCE": os.path.join(base_path, rag_config['legal_source_folder']),
            "CASE_SOURCE": os.path.join(base_path, rag_config['case_source_folder']),
            "LEGAL_DB": os.path.join(base_path, rag_config['vector_db_legal_folder']),
            "CASE_DB": os.path.join(base_path, rag_config['vector_db_case_folder']),
            "LOG_FOLDER": os.path.join(base_path, rag_config['log_folder']),
            "EMBEDDING_MODEL": rag_config['embedding_model'],
            "LLM_MODEL": rag_config['llm_model']
        }
        print("English: Configuration loaded successfully.\nPolski: Konfiguracja załadowana pomyślnie.")
        return conf
    except Exception as e:
        print(
            f"English: FATAL ERROR loading configuration from {config_path}: {e}\nPolski: KRYTYCZNY BŁĄD podczas ładowania konfiguracji z {config_path}: {e}")
        return None


# --- Global Initialization ---
# --- Globalna Inicjalizacja ---
CONFIG = load_configuration()
if CONFIG:
    logger = setup_logger(CONFIG['LOG_FOLDER'])
    LLM = GoogleGenerativeAI(model=CONFIG['LLM_MODEL'], google_api_key=CONFIG['GOOGLE_API_KEY'])
    EMBEDDINGS = GoogleGenerativeAIEmbeddings(model=CONFIG['EMBEDDING_MODEL'], google_api_key=CONFIG['GOOGLE_API_KEY'])
else:
    logger = setup_logger('LOGS')


def initialize_vector_store(db_path: str, source_folder: str, corpus_type: str,
                            force_rebuild: bool = False) -> Chroma | None:
    """
    Initializes a Chroma vector store. Builds it if it doesn't exist or if rebuild is forced.
    Inicjalizuje bazę wektorową Chroma. Buduje ją, jeśli nie istnieje lub wymuszono przebudowę.
    """
    if os.path.exists(db_path) and not force_rebuild:
        logger.info(f"Loading existing vector database from: {db_path}")
        print(
            f"English: Loading existing vector database from: {db_path}\nPolski: Ładuję istniejącą bazę wektorową z: {db_path}")
        try:
            db = Chroma(persist_directory=db_path, embedding_function=EMBEDDINGS)
            return db
        except Exception as e:
            logger.error(
                f"Failed to load existing database at {db_path}. It might be corrupted. Try rebuilding. Error: {e}")
            print(
                f"English: ERROR - Failed to load existing database at {db_path}. Try rebuilding. Error: {e}\nPolski: BŁĄD - Nie udało się załadować istniejącej bazy z {db_path}. Spróbuj ją przebudować. Błąd: {e}")
            return None

    logger.info(f"Rebuilding vector database for corpus '{corpus_type}'...")
    print(
        f"English: Rebuilding vector database for corpus '{corpus_type}'...\nPolski: Przebudowuję bazę wektorową dla korpusu '{corpus_type}'...")

    if os.path.exists(db_path):
        shutil.rmtree(db_path)

    documents = get_documents_from_source(source_folder, corpus_type)
    if not documents:
        logger.error(f"No documents found for corpus '{corpus_type}'. Database not built.")
        print(
            f"English: ERROR - No documents found for corpus '{corpus_type}'. Database not built.\nPolski: BŁĄD - Nie znaleziono dokumentów dla korpusu '{corpus_type}'. Baza danych nie została zbudowana.")
        return None

    db = Chroma.from_documents(documents, EMBEDDINGS, persist_directory=db_path)
    logger.info(f"Successfully built and saved vector database at: {db_path}")
    print(
        f"English: Successfully built and saved vector database at: {db_path}\nPolski: Pomyślnie zbudowano i zapisano bazę wektorową w: {db_path}")
    return db


def format_docs(docs: list) -> str:
    """
    Helper function to format retrieved documents for the prompt, including metadata.
    Funkcja pomocnicza do formatowania pobranych dokumentów na potrzeby promptu, włączając metadane.
    """
    formatted_docs = []
    for doc in docs:
        if doc.metadata.get("type") == "legal_corpus":
            header = f"Fragment z prawa: {doc.metadata.get('source', 'b.d.')}, Artykuł: {doc.metadata.get('article', 'b.d.')}"
        elif doc.metadata.get("type") == "case_corpus":
            header = f"Fragment z dowodu: {doc.metadata.get('source_original', 'b.d.')} (w archiwum: {doc.metadata.get('source_archive', 'b.d.')})"
        else:
            header = "Fragment z nieznanego źródła"

        content = doc.page_content
        formatted_docs.append(f"{header}\n---\n{content}\n---\n")
    return "\n".join(formatted_docs)


def perform_legal_analysis(query: str, legal_retriever, case_retriever):
    """
    Performs a multi-step RAG query to synthesize facts and law.
    Wykonuje wieloetapowe zapytanie RAG w celu syntezy faktów i prawa.
    """
    logger.info(f"Performing full legal analysis for query: '{query[:80]}...'")
    print(
        f"English: Performing full legal analysis for query: '{query[:80]}...'\nPolski: Wykonuję pełną analizę prawną dla zapytania: '{query[:80]}...'")

    logger.info("Step 1: Retrieving facts from case_db...")
    print(
        "English: Step 1: Retrieving facts from case database...\nPolski: Krok 1: Pobieram fakty z bazy danych sprawy...")
    factual_context_docs = case_retriever.invoke(query)
    factual_context_str = format_docs(factual_context_docs)

    logger.info("Step 2: Retrieving law from legal_db...")
    print(
        "English: Step 2: Retrieving law from legal database...\nPolski: Krok 2: Pobieram prawo z bazy danych prawnej...")
    legal_context_docs = legal_retriever.invoke(query)
    legal_context_str = format_docs(legal_context_docs)

    logger.info("Step 3: Synthesizing final answer with LLM...")
    print(
        "English: Step 3: Synthesizing final answer with LLM...\nPolski: Krok 3: Syntezuję ostateczną odpowiedź za pomocą LLM...")

    final_template = """Jesteś ekspertem prawnym i analitykiem. Twoim zadaniem jest staranna analiza przedstawionego stanu faktycznego w świetle załączonych przepisów prawnych, aby odpowiedzieć na pytanie użytkownika. Odpowiedź musi być spójna, logiczna i odwoływać się zarówno do faktów, jak i do prawa, cytując źródła w nawiasach kwadratowych po każdej informacji, np. [źródło: KODEKS_KARNY.pdf, Art. 148].

PYTANIE UŻYTKOWNIKA:
{question}

ZEBRANE FAKTY (Z DOKUMENTÓW SPRAWY):
{factual_context}

ZEBRANE PRZEPISY PRAWNE:
{legal_context}

KOMPLEKSOWA ANALIZA PRAWNA:"""

    prompt = PromptTemplate.from_template(final_template)

    analysis_chain = prompt | LLM | StrOutputParser()

    response = analysis_chain.invoke({
        "question": query,
        "factual_context": factual_context_str,
        "legal_context": legal_context_str
    })

    print("\n" + "=" * 25 + " WYNIK ANALIZY " + "=" * 25)
    print(response)
    print("=" * 65 + "\n")


if __name__ == "__main__":
    if not CONFIG:
        logger.critical("Configuration failed to load. Exiting.")
        print(
            "English: FATAL - Configuration failed to load. Exiting.\nPolski: BŁĄD KRYTYCZNY - Nie udało się wczytać konfiguracji. Zamykanie.")
        exit()

    # --- Rebuild Flags ---
    # Ustaw na True, jeśli chcesz wymusić przebudowanie konkretnej bazy
    # Set to True if you want to force a rebuild of a specific database
    REBUILD_LEGAL_DB = False
    REBUILD_CASE_DB = False

    legal_db = initialize_vector_store(
        db_path=CONFIG['LEGAL_DB'],
        source_folder=CONFIG['LEGAL_SOURCE'],
        corpus_type='legal',
        force_rebuild=REBUILD_LEGAL_DB
    )

    case_db = initialize_vector_store(
        db_path=CONFIG['CASE_DB'],
        source_folder=CONFIG['CASE_SOURCE'],
        corpus_type='case',
        force_rebuild=REBUILD_CASE_DB
    )

    if not legal_db or not case_db:
        logger.critical("One or more databases failed to initialize. Cannot proceed with queries.")
        print(
            "English: CRITICAL - One or more databases failed to initialize. Cannot proceed.\nPolski: BŁĄD KRYTYCZNY - Inicjalizacja jednej lub więcej baz danych nie powiodła się. Nie można kontynuować.")
    else:
        legal_retriever = legal_db.as_retriever(search_kwargs={'k': 5})
        case_retriever = case_db.as_retriever(search_kwargs={'k': 8})

        # --- Ask your question here ---
        # --- Zadaj swoje pytanie tutaj ---
        user_question = "Jakie prawa gwarantowane przez Konstytucję RP mogły zostać naruszone, biorąc pod uwagę treść moich pism, w których opisuję brak środków do życia i problemy zdrowotne?"

        perform_legal_analysis(
            query=user_question,
            legal_retriever=legal_retriever,
            case_retriever=case_retriever
        )
--- END FILE: RAG/rag_query_assistant_test1.py ---

--- START FILE: RAG/rag_data_preprocessor.py ---
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# --- Libraries / Biblioteki ---

# For filesystem operations, e.g., creating paths and checking existence.
# Do operacji na systemie plików, np. tworzenia ścieżek i sprawdzania istnienia.
import os

# For using regular expressions to split text based on patterns.
# Do używania wyrażeń regularnych do dzielenia tekstu na podstawie wzorców.
import re

# For creating and managing logs (to console and file).
# Do tworzenia i zarządzania logami (do konsoli i pliku).
import logging
from logging.handlers import RotatingFileHandler

# LangChain's standard data structure for a piece of text with metadata.
# Standardowa struktura danych LangChain dla fragmentu tekstu z metadanymi.
from langchain.schema.document import Document

# LangChain's tool for splitting large texts into smaller, overlapping chunks.
# Narzędzie LangChain do dzielenia dużych tekstów na mniejsze, nakładające się fragmenty.
from langchain.text_splitter import RecursiveCharacterTextSplitter

# A robust library for extracting text and data from PDF files.
# Solidna biblioteka do wyciągania tekstu i danych z plików PDF.
import pdfplumber


def setup_logger(log_folder: str):
    """
    Sets up a logger to output to both console and a rotating file.
    Konfiguruje logger do zapisu zarówno do konsoli, jak i do rotacyjnego pliku.
    """
    if not os.path.exists(log_folder):
        os.makedirs(log_folder)

    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # Prevents adding multiple handlers if the function is called more than once
    # Zapobiega dodawaniu wielu handlerów, jeśli funkcja zostanie wywołana więcej niż raz
    if logger.hasHandlers():
        logger.handlers.clear()

    # Console handler
    # Handler konsoli
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)

    # File handler
    # Handler pliku
    fh = RotatingFileHandler(
        os.path.join(log_folder, 'rag_preprocessor.log'),
        maxBytes=5 * 1024 * 1024,  # 5 MB
        backupCount=3
    )
    fh.setLevel(logging.INFO)

    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    fh.setFormatter(formatter)

    logger.addHandler(ch)
    logger.addHandler(fh)

    return logger


# Initialize logger here, assuming a LOGS folder exists at the project root for now
# Inicjalizacja loggera, zakładając na razie folder LOGS w głównym katalogu projektu
logger = setup_logger('LOGS')


def process_legal_document(file_path: str) -> list[Document]:
    """
    Processes a structured legal PDF, splitting it by articles.
    Przetwarza ustrukturyzowany prawny plik PDF, dzieląc go na artykuły.
    """
    file_name = os.path.basename(file_path)
    logger.info(f"Processing legal document: {file_name}")
    print(f"English: Processing legal document: {file_name}\nPolski: Przetwarzam dokument prawny: {file_name}")

    try:
        with pdfplumber.open(file_path) as pdf:
            full_text = "\n".join(page.extract_text() or "" for page in pdf.pages)
    except Exception as e:
        logger.error(f"Could not read PDF file {file_path}: {e}")
        print(
            f"English: ERROR - Could not read PDF file {file_path}: {e}\nPolski: BŁĄD - Nie można odczytać pliku PDF {file_path}: {e}")
        return []

    chunks = re.split(r'(?=\nArt\.\s*\d+[a-zA-Z]?\.?)', full_text)

    documents = []
    for chunk in chunks:
        if not chunk.strip():
            continue

        match = re.search(r'^(Art\.\s*\d+[a-zA-Z]?\.?)', chunk)
        article_num = match.group(1).strip() if match else "N/A"

        doc = Document(
            page_content=chunk.strip(),
            metadata={
                "source": file_name,
                "article": article_num,
                "type": "legal_corpus"
            }
        )
        documents.append(doc)

    logger.info(f"  > Found and processed {len(documents)} articles/fragments.")
    print(
        f"English:   > Found and processed {len(documents)} articles/fragments.\nPolski:   > Znaleziono i przetworzono {len(documents)} artykułów/fragmentów.")
    return documents


def process_case_document_archive(file_path: str) -> list[Document]:
    """
    Processes a 'Combined_Content' PDF. It splits the content back into its
    original source files in memory, then chunks them.
    Przetwarza plik PDF typu 'Combined_Content'. Dzieli zawartość z powrotem na
    oryginalne pliki w pamięci, a następnie je chunkuje.
    """
    archive_name = os.path.basename(file_path)
    logger.info(f"Processing case document archive: {archive_name}")
    print(
        f"English: Processing case document archive: {archive_name}\nPolski: Przetwarzam archiwum dokumentów sprawy: {archive_name}")

    try:
        with pdfplumber.open(file_path) as pdf:
            full_text = "\n".join(page.extract_text() or "" for page in pdf.pages)
    except Exception as e:
        logger.error(f"Could not read PDF archive file {file_path}: {e}")
        print(
            f"English: ERROR - Could not read PDF archive file {file_path}: {e}\nPolski: BŁĄD - Nie można odczytać pliku archiwum PDF {file_path}: {e}")
        return []

    parts = re.split(r'--- BEGINNING OF FILE: (.*?) ---', full_text)

    documents = []
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)

    for i in range(1, len(parts), 2):
        original_filename = parts[i].strip()
        content = parts[i + 1].split('--- END OF FILE:')[0].strip()

        logger.info(f"  > Extracting virtual file: {original_filename}")
        print(
            f"English:   > Extracting virtual file: {original_filename}\nPolski:   > Ekstrahuję wirtualny plik: {original_filename}")

        if not content:
            logger.warning(f"    > Content for {original_filename} is empty. Skipping.")
            print(
                f"English:     > Content for {original_filename} is empty. Skipping.\nPolski:     > Zawartość dla {original_filename} jest pusta. Pomijam.")
            continue

        chunks = text_splitter.split_text(content)

        for chunk_content in chunks:
            doc = Document(
                page_content=chunk_content,
                metadata={
                    "source_original": original_filename,
                    "source_archive": archive_name,
                    "type": "case_corpus"
                }
            )
            documents.append(doc)

    logger.info(f"  > Extracted {len(documents)} total chunks from the archive.")
    print(
        f"English:   > Extracted {len(documents)} total chunks from the archive.\nPolski:   > Wyekstrahowano {len(documents)} wszystkich chunków z archiwum.")
    return documents


def get_documents_from_source(source_folder: str, corpus_type: str) -> list[Document]:
    """
    Main orchestrator function for the preprocessing step.
    Główna funkcja orkiestrująca dla kroku preprocessingu.
    """
    all_processed_docs = []

    logger.info(f"Starting data preprocessing for corpus '{corpus_type}' from folder: {source_folder}")
    print(
        f"\nEnglish: Starting data preprocessing for corpus '{corpus_type}' from folder: {source_folder}\nPolski: Rozpoczynam preprocessing danych dla korpusu '{corpus_type}' z folderu: {source_folder}")

    if not os.path.exists(source_folder):
        logger.error(f"Source folder not found: {source_folder}")
        print(
            f"English: ERROR - Source folder not found: {source_folder}\nPolski: BŁĄD - Folder źródłowy nie znaleziony: {source_folder}")
        return []

    for file_name in os.listdir(source_folder):
        if file_name.lower().endswith(".pdf"):
            file_path = os.path.join(source_folder, file_name)
            if corpus_type == 'legal':
                processed_docs = process_legal_document(file_path)
            elif corpus_type == 'case':
                processed_docs = process_case_document_archive(file_path)
            else:
                logger.warning(f"Unknown corpus type '{corpus_type}'. Skipping file {file_name}.")
                print(
                    f"English: WARNING - Unknown corpus type '{corpus_type}'. Skipping file {file_name}.\nPolski: OSTRZEŻENIE - Nieznany typ korpusu '{corpus_type}'. Pomijam plik {file_name}.")
                processed_docs = []
            all_processed_docs.extend(processed_docs)

    logger.info(f"Finished preprocessing for '{corpus_type}'. Total documents prepared: {len(all_processed_docs)}")
    print(
        f"English: Finished preprocessing for '{corpus_type}'. Total documents prepared: {len(all_processed_docs)}\nPolski: Zakończono preprocessing dla '{corpus_type}'. Łączna liczba przygotowanych dokumentów: {len(all_processed_docs)}\n")
    return all_processed_docs
--- END FILE: RAG/rag_data_preprocessor.py ---

--- START FILE: RAG/rag_query_assistant_test.py ---
# --- Importing necessary libraries ---
# --- Importowanie niezbędnych bibliotek ---
import os  # Do operacji na systemie plików / For filesystem operations
import yaml  # Do wczytywania plików konfiguracyjnych / For loading configuration files
import shutil  # Do operacji na plikach wysokiego poziomu, np. usuwania folderów / For high-level file operations, e.g., removing directories
import time  # Do mierzenia czasu wykonania / For measuring execution time
import json  # Do pracy z plikami JSON (zapis logów) / For working with JSON files (log saving)
from datetime import datetime  # Do generowania znaczników czasu / For generating timestamps
# Biblioteki LangChain do integracji z Google Gemini
# LangChain libraries for Google Gemini integration
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings
# Biblioteka LangChain do przechowywania wektorów w ChromaDB
# LangChain library for storing vectors in ChromaDB
#from langchain.vectorstores.chroma import Chroma
from langchain_community.vectorstores import Chroma
# Biblioteka LangChain do ładowania dokumentów z folderu
# LangChain library for loading documents from a directory
from langchain_community.document_loaders import DirectoryLoader
# Biblioteka LangChain do dzielenia tekstu na fragmenty (chunks)
# LangChain library for splitting text into chunks
from langchain.text_splitter import RecursiveCharacterTextSplitter
# Biblioteki LangChain do budowania łańcucha RAG (prompt, przekazywanie danych, parser odpowiedzi)
# LangChain libraries for building the RAG chain (prompt, data passthrough, output parser)
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser


# --- Main Configuration Loading ---
# --- Główne ładowanie konfiguracji ---
def load_configuration():
    """
    Wczytuje konfigurację z pliku scripts/config.yaml i zwraca ją jako słownik.
    Loads configuration from scripts/config.yaml file and returns it as a dictionary.
    """
    config_path = os.path.join(os.path.dirname(__file__), '..', 'scripts', 'config.yaml')
    if not os.path.exists(config_path): config_path = "scripts/config.yaml"

    try:
        with open(config_path, "r", encoding="utf-8") as cr:
            config = yaml.full_load(cr)
        conf = {
            "GOOGLE_API_KEY": config['KEY'],
            "BASE_PATH": config['base_path'],
            "TEXT_CACHE_FOLDER": os.path.join(config['base_path'], config['rag_pipeline_config']['text_cache_folder']),
            "VECTOR_DB_FOLDER": os.path.join(config['base_path'], config['rag_pipeline_config']['vector_db_folder']),
            "LOG_FOLDER": os.path.join(config['base_path'], "LOGS"),
            "EMBEDDING_MODEL": config['rag_pipeline_config']['embedding_model'],
            "LLM_MODEL": config['rag_pipeline_config']['llm_model']
        }
        print("Konfiguracja dla asystenta RAG załadowana pomyślnie.")
        print("RAG assistant configuration loaded successfully.")
        return conf
    except Exception as e:
        print(f"FATAL ERROR in configuration from path {config_path}: {e}")
        return None


# --- Log Management Function ---
# --- Funkcja Zarządzania Logami ---
def save_session_log(log_folder, log_data):
    """
    Zapisuje log z sesji zapytań i odpowiedzi do pliku JSON.
    Saves the query and answer session log to a JSON file.
    """
    session_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file_path = os.path.join(log_folder, f"rag_query_assistant_log_{session_timestamp}.json")
    try:
        with open(log_file_path, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=4, ensure_ascii=False)
        print(f"\nLog sesji zapytań zapisano do: {log_file_path}")
        print(f"Query session log saved to: {log_file_path}")
    except IOError as e:
        print(f"BŁĄD: Nie można zapisać pliku logu sesji: {e}")
        print(f"ERROR: Could not write session log file: {e}")


# --- Initialization ---
# --- Inicjalizacja ---
CONFIG = load_configuration()
LLM = None
EMBEDDINGS = None
if CONFIG:
    try:
        LLM = GoogleGenerativeAI(model=CONFIG['LLM_MODEL'], google_api_key=CONFIG['GOOGLE_API_KEY'])
        EMBEDDINGS = GoogleGenerativeAIEmbeddings(model=CONFIG['EMBEDDING_MODEL'],
                                                  google_api_key=CONFIG['GOOGLE_API_KEY'])
        os.makedirs(CONFIG['LOG_FOLDER'], exist_ok=True)
        print("Modele Gemini (LLM i Embeddings) gotowe do pracy.")
        print("Gemini model (LLM and Embeddings) are ready.")
    except Exception as e:
        print(f"BŁĄD: Nie można skonfigurować Gemini API: {e}")
        CONFIG = None


# --- Core RAG Functions ---
# --- Główne funkcje RAG ---
def build_vector_store_from_cache(session_log_ref):
    """
    Buduje (lub przebudowuje) bazę wektorową na podstawie plików .txt z folderu cache.
    Builds (or rebuilds) the vector store based on .txt files from the cache folder.
    """
    if not CONFIG: return

    start_time = time.time()
    log_entry = {"action": "build_vector_store", "start_utc": datetime.utcnow().isoformat(), "status": "In-Progress"}

    try:
        vector_db_path = CONFIG['VECTOR_DB_FOLDER']
        if os.path.exists(vector_db_path): shutil.rmtree(vector_db_path); print(
            f"Usunięto istniejącą bazę danych w: {vector_db_path}")

        loader = DirectoryLoader(CONFIG['TEXT_CACHE_FOLDER'], glob="**/*.txt", recursive=True)
        documents = loader.load()
        if not documents: raise FileNotFoundError(
            "Folder cache jest pusty. Uruchom najpierw 'rag_data_preprocessor.py'.")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
        docs = text_splitter.split_documents(documents)
        print(f"Budowanie bazy wektorowej z {len(docs)} fragmentów...");
        print(f"Building vector store from {len(docs)} chunks...")

        Chroma.from_documents(documents=docs, embedding=EMBEDDINGS, persist_directory=vector_db_path)
        log_entry["status"] = "Success"
        print(f"Baza wektorowa została pomyślnie zbudowana w: {vector_db_path}")

    except Exception as e:
        log_entry["status"] = "Failed";
        log_entry["error_message"] = str(e)
        print(f"KRYTYCZNY BŁĄD podczas budowania bazy wektorowej: {e}")

    log_entry["duration_seconds"] = round(time.time() - start_time, 2)
    session_log_ref["database_build_event"] = log_entry


def ask_assistant(query: str, session_log_ref):
    """
    Zadaje pytanie do istniejącej bazy wektorowej i zwraca odpowiedź.
    Asks a question to the existing vector store and returns the answer.
    """
    if not CONFIG: return

    start_time = time.time()
    log_entry = {"query": query}

    try:
        vector_db_path = CONFIG['VECTOR_DB_FOLDER']
        if not os.path.exists(vector_db_path): raise FileNotFoundError("Baza wektorowa nie istnieje.")

        vector_db = Chroma(persist_directory=vector_db_path, embedding_function=EMBEDDINGS)
        retriever = vector_db.as_retriever(search_kwargs={'k': 15})

        template = """Jesteś ekspertem prawnym specjalizującym się w analizie dokumentów. Odpowiedz na pytanie użytkownika precyzyjnie i wyłącznie na podstawie dostarczonego poniżej kontekstu. Jeśli w kontekście brakuje odpowiedzi, poinformuj o tym jasno. Cytuj kluczowe fakty.

KONTEKST Z TWOJEJ BAZY WIEDZY:
{context}

PYTANIE UŻYTKOWNIKA:
{question}

PRECYZYJNA ODPOWIEDŹ:"""
        prompt = PromptTemplate.from_template(template)

        rag_chain = (
                {"context": retriever, "question": RunnablePassthrough()}
                | prompt
                | LLM
                | StrOutputParser()
        )

        print("\n=======================================================")
        print(f"PYTANIE: {query}");
        print("---")

        response = rag_chain.invoke(query)
        print(f"ODPOWIEDŹ ASYSTENTA:\n{response}")

        log_entry["response"] = response;
        log_entry["status"] = "Success"

    except Exception as e:
        error_message = f"BŁĄD podczas przetwarzania zapytania: {e}";
        print(error_message)
        log_entry["response"] = error_message;
        log_entry["status"] = "Failed"

    log_entry["duration_seconds"] = round(time.time() - start_time, 2)
    session_log_ref["queries_asked"].append(log_entry)
    print("=======================================================\n")


# --- Main Execution ---
# --- Główne wykonanie ---
if __name__ == "__main__":
    """
    Główny blok wykonawczy skryptu. Pozwala na budowę bazy lub zadawanie pytań.
    Main execution block of the script. Allows building the database or asking questions.
    """
    session_log_data = {"session_start_utc": datetime.utcnow().isoformat(), "database_build_event": None,
                        "queries_asked": []}

    try:
        # === KROK 1: Budowanie bazy wektorowej (jednorazowo) ===
        # === STEP 1: Building the vector store (one-time) ===
        #build_vector_store_from_cache(session_log_data)

        # === KROK 2: Zadawanie pytań ===
        # === STEP 2: Asking questions ===
        if CONFIG and os.path.exists(CONFIG["VECTOR_DB_FOLDER"]):
            ask_assistant(
                "Czy posiadasz w bazie Konstytucję RP?",
                session_log_data)
            ask_assistant("Jesli tak - znajdź artykuł 13 i opisz mi jego znaczenie",
                          session_log_data)
        else:
            print(
                "\nBaza wektorowa nie istnieje. Uruchom najpierw `rag_data_preprocessor.py`, a następnie odkomentuj funkcję `build_vector_store_from_cache()` w tym skrypcie i uruchom go.")
            print(
                "Vector store does not exist. First run `rag_data_preprocessor.py`, then uncomment the `build_vector_store_from_cache()` function in this script and run it.")

    finally:
        # Zapisz log całej sesji na koniec
        # Save the entire session log at the end
        save_session_log(CONFIG['LOG_FOLDER'], session_log_data)
--- END FILE: RAG/rag_query_assistant_test.py ---

--- START FILE: scripts/gemini_api_connection_test.py ---
import uno
import unohelper
import json
import http.client  # For making HTTP requests
import yaml

with open("config.yaml", "r") as cr:
    config_vals = yaml.full_load(cr)
KEY = config_vals['KEY']

# Main macro function to test Google Gemini API connection
# Główna funkcja makra do testowania połączenia z API Google Gemini
def test_gemini_connection(*args):
    # --- GEMINI API KEY CONFIGURATION ---
    # --- KONFIGURACJA KLUCZA API GEMINI ---
    # IMPORTANT: Replace "*****" with your real API key in config.yaml!
    # WAŻNE: Zastąp "*****" swoim prawdziwym kluczem API w pliku config.yaml!
    GOOGLE_API_KEY = KEY
    print("Gemini API configured successfully.")
    print("Gemini API skonfigurowane pomyślnie.")

    API_HOST = "generativelanguage.googleapis.com"
    MODEL_NAME = "gemini-1.5-flash-8b"  # Using a simple model for testing
    # Używamy prostego modelu do testu

    # A very simple prompt to test the connection
    # Bardzo prosty prompt do przetestowania połączenia
    test_prompt = "Say 'OK'." # English version for the model
    test_prompt_pl = "Powiedz 'OK'." # Polish version for clarity in context

    request_body = {
        "contents": [
            {
                "parts": [
                    {"text": test_prompt_pl} # Use the Polish prompt for the model
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.0,  # Low temperature for predictable output
            # Niska temperatura dla przewidywalnego wyniku
            "maxOutputTokens": 50,  # Short response
            # Krótka odpowiedź
        }
    }

    try:
        conn = http.client.HTTPSConnection(API_HOST)
        headers = {
            'Content-Type': 'application/json',
            'x-goog-api-key': GOOGLE_API_KEY
        }

        endpoint = f"/v1beta/models/{MODEL_NAME}:generateContent"
        body = json.dumps(request_body)

        print(f"Testing connection to Google Gemini API at {API_HOST}{endpoint}...")
        print(f"Testuję połączenie z Google Gemini API na {API_HOST}{endpoint}...")

        conn.request("POST", endpoint, body=body, headers=headers)
        response = conn.getresponse()
        response_data = response.read().decode('utf-8')
        conn.close()

        print(f"Gemini API Response Status: {response.status}")
        print(f"Status odpowiedzi API Gemini: {response.status}")
        print(f"Full Gemini API Response (for diagnostics): {response_data}")
        print(f"Pełna odpowiedź API Gemini (do diagnostyki): {response_data}")

        if response.status == 200:
            result = json.loads(response_data)
            # Check if the response contains the expected text
            # Sprawdzamy, czy odpowiedź zawiera oczekiwany tekst
            if 'candidates' in result and len(result['candidates']) > 0 \
                    and 'content' in result['candidates'][0] \
                    and 'parts' in result['candidates'][0]['content'] \
                    and len(result['candidates'][0]['content']['parts']) > 0 \
                    and 'text' in result['candidates'][0]['content']['parts'][0]:

                model_response = result['candidates'][0]['content']['parts'][0]['text'].strip()
                if "OK" in model_response.upper():  # Check if the model returned "OK"
                    # Sprawdzamy, czy model zwrócił "OK"
                    print("SUCCESS: Connection to Google Gemini API successful! Model responded: " + model_response)
                    print("SUKCES: Połączenie z Google Gemini API zakończone sukcesem! Model odpowiedział: " + model_response)
                else:
                    print(f"WARNING: Google Gemini API connection successful, but model did not return 'OK'. Response: {model_response}")
                    print(f"OSTRZEŻENIE: Połączenie z Google Gemini API zakończone sukcesem, ale model nie zwrócił 'OK'. Odpowiedź: {model_response}")
            else:
                print(f"ERROR: Successful connection, but invalid Gemini response structure. Status: {response.status}")
                print(f"BŁĄD: Pomyślne połączenie, ale nieprawidłowa struktura odpowiedzi Gemini. Status: {response.status}")

        elif response.status == 400:  # Bad Request (e.g., wrong API key, bad request format)
            # Bad Request (np. błędny klucz API, zły format zapytania)
            error_details = json.loads(response_data).get('error', {}).get('message', 'No details available.')
            # Brak szczegółów.
            print(f"ERROR: Gemini API Error (400 - Bad Request). Check API key and request format. Details: {error_details}")
            print(f"BŁĄD: Błąd API Gemini (400 - Bad Request). Sprawdź klucz API i format zapytania. Szczegóły: {error_details}")
        elif response.status == 403:  # Forbidden (e.g., API key lacks permissions or API is not enabled)
            # Forbidden (np. klucz API nie ma uprawnień lub API nie jest włączone)
            print(f"ERROR: Gemini API Error (403 - Forbidden). API key might lack permissions or API is not enabled. Response: {response_data}")
            print(f"BŁĄD: Błąd API Gemini (403 - Forbidden). Klucz API może nie mieć uprawnień lub API nie jest włączone. Odpowiedź: {response_data}")
        elif response.status == 404:  # Not Found (e.g., wrong URL, model does not exist)
            # Not Found (np. zły URL, model nie istnieje)
            print(f"ERROR: Gemini API Error (404 - Not Found). Check model name ({MODEL_NAME}) or API address. Response: {response_data}")
            print(f"BŁĄD: Błąd API Gemini (404 - Not Found). Sprawdź nazwę modelu ({MODEL_NAME}) lub adres API. Odpowiedź: {response_data}")
        else:
            print(f"ERROR: Google Gemini server error: HTTP {response.status} - {response_data}")
            print(f"BŁĄD: Błąd z serwera Google Gemini: HTTP {response.status} - {response_data}")

    except Exception as e:
        print(f"CRITICAL ERROR: During communication with Google Gemini: {e}")
        print(f"KRYTYCZNY BŁĄD: Podczas komunikacji z Google Gemini: {e}")


# Register the macro for LibreOffice
# Rejestracja makra dla LibreOffice
g_exportedScripts = test_gemini_connection,
--- END FILE: scripts/gemini_api_connection_test.py ---

--- START FILE: scripts/upload_folders-google_drive.py ---
import os
import yaml
from datetime import datetime
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive


def upload_folder_to_drive(drive, local_path, parent_folder_id, folder_name):
    """
    # Uploads a local folder and its contents to Google Drive.
    # Przesyła lokalny folder i jego zawartość na Google Drive.
    """
    # Create the folder on Google Drive
    # Utwórz folder na Google Drive
    folder_metadata = {
        'title': folder_name,
        'mimeType': 'application/vnd.google-apps.folder',
        'parents': [{'id': parent_folder_id}]
    }
    folder = drive.CreateFile(folder_metadata)
    folder.Upload()
    print(f"Created folder on Google Drive: '{folder_name}' (ID: {folder['id']})")
    print(f"Utworzono folder na Google Drive: '{folder_name}' (ID: {folder['id']})")

    # Upload files and subfolders
    # Prześlij pliki i podfoldery
    for item_name in os.listdir(local_path):
        item_path = os.path.join(local_path, item_name)
        if os.path.isfile(item_path):
            # Upload file
            # Prześlij plik
            file_metadata = {
                'title': item_name,
                'parents': [{'id': folder['id']}]
            }
            gfile = drive.CreateFile(file_metadata)
            gfile.SetContentFile(item_path)
            gfile.Upload()
            print(f"  Uploaded file: '{item_name}'")
            print(f"  Przesłano plik: '{item_name}'")
        elif os.path.isdir(item_path):
            # Recursively upload subfolder
            # Rekurencyjnie prześlij podfolder
            print(f"  Uploading subfolder: '{item_name}'...")
            print(f"  Przesyłam podfolder: '{item_name}'...")
            upload_folder_to_drive(drive, item_path, folder['id'], item_name)


def main():
    # Load configuration
    # Wczytaj konfigurację
    try:
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        print("Error: 'config.yaml' file not found. Make sure it exists in the same directory as the script.")
        print("Błąd: Plik 'config.yaml' nie znaleziony. Upewnij się, że istnieje w tym samym katalogu co skrypt.")
        return
    except yaml.YAMLError as e:
        print(f"Error parsing 'config.yaml' file: {e}")
        print(f"Błąd podczas parsowania pliku 'config.yaml': {e}")
        return

    folders_to_check = config.get('folders_to_check', [])
    base_path = config.get('base_path', os.getcwd())
    google_drive_parent_folder_id = config.get('google_drive_parent_folder_id')

    if not google_drive_parent_folder_id:
        print("Error: 'google_drive_parent_folder_id' not found in config.yaml.")
        print("Błąd: 'google_drive_parent_folder_id' nie został znaleziony w pliku config.yaml.")
        return

    # Authenticate with Google Drive
    # Uwierzytelnij się z Google Drive
    gauth = GoogleAuth()
    # Try to load saved credentials
    # Spróbuj załadować zapisane poświadczenia
    gauth.LoadCredentialsFile("credentials.json")
    if gauth.credentials is None:
        # Authenticate if no credentials found
        # Uwierzytelnij, jeśli nie znaleziono poświadczeń
        gauth.LocalWebserverAuth()
    elif gauth.access_token_expired:
        # Refresh token if expired
        # Odśwież token, jeśli wygasł
        gauth.Refresh()
    else:
        # Initialize the saved creds
        # Zainicjuj zapisane poświadczenia
        gauth.Authorize()
    gauth.SaveCredentialsFile(
        "credentials.json")  # Save credentials for next run / Zapisz poświadczenia do następnego uruchomienia

    drive = GoogleDrive(gauth)

    # Get current date for the target folder name
    # Pobierz aktualną datę dla nazwy folderu docelowego
    current_date_folder_name = datetime.now().strftime("%Y-%m-%d")

    # Create the main date folder on Google Drive
    # Utwórz główny folder z datą na Google Drive
    date_folder_metadata = {
        'title': current_date_folder_name,
        'mimeType': 'application/vnd.google-apps.folder',
        'parents': [{'id': google_drive_parent_folder_id}]
    }
    date_folder = drive.CreateFile(date_folder_metadata)
    date_folder.Upload()
    print(f"\nMain folder created on Google Drive: '{current_date_folder_name}' (ID: {date_folder['id']})")
    print(f"\nUtworzono główny folder na Google Drive: '{current_date_folder_name}' (ID: {date_folder['id']})")

    # Check and upload folders
    # Sprawdź i prześlij foldery
    for folder_name in folders_to_check:
        full_path = os.path.join(base_path, folder_name)
        print(f"\nChecking folder: '{full_path}'")
        print(f"\nSprawdzam folder: '{full_path}'")

        if not os.path.exists(full_path):
            print(f"  Folder does not exist. Skipping.")
            print(f"  Folder nie istnieje. Pomijam.")
            continue

        if not os.path.isdir(full_path):
            print(f"  This is not a directory. Skipping.")
            print(f"  To nie jest katalog. Pomijam.")
            continue

        if not os.listdir(full_path):
            print(f"  Folder is empty. Skipping.")
            print(f"  Folder jest pusty. Pomijam.")
        else:
            print(f"  Folder is not empty. Starting upload...")
            print(f"  Folder nie jest pusty. Rozpoczynam przesyłanie...")
            try:
                upload_folder_to_drive(drive, full_path, date_folder['id'], folder_name)
                print(f"  Finished uploading folder '{folder_name}'.")
                print(f"  Zakończono przesyłanie folderu '{folder_name}'.")
            except Exception as e:
                print(f"  An error occurred while uploading folder '{folder_name}': {e}")
                print(f"  Wystąpił błąd podczas przesyłania folderu '{folder_name}': {e}")

    print("\nProcess finished.")
    print("\nProces zakończony.")


if __name__ == '__main__':
    main()
--- END FILE: scripts/upload_folders-google_drive.py ---

--- START FILE: scripts/google_drive_auth.py ---
from pydrive2.auth import GoogleAuth

gauth = GoogleAuth()
gauth.LocalWebserverAuth() # This will open a browser for authentication / To otworzy przeglądarkę do uwierzytelnienia
print("Authentication successful!") # Uwierzytelnienie zakończone sukcesem!
--- END FILE: scripts/google_drive_auth.py ---

--- START FILE: scripts/audio-text.py ---
import os
import google.generativeai as genai
import datetime
import time
import json  # Added for JSON log saving / Dodane do zapisu logów w formacie JSON
import yaml

with open("config.yaml", "r") as cr:
    config_vals = yaml.full_load(cr)
KEY = config_vals['KEY']

# --- PATH CONFIGURATION ---
# --- KONFIGURACJA ŚCIEŻEK ---
# Folder for input audio files.
# Folder na wejściowe pliki audio.
AUDIO_INPUT_FOLDER = os.path.join(os.path.dirname(__file__), "audio_input")
# Folder for output transcription and analysis results.
# Folder na wyniki transkrypcji i analizy.
AUDIO_OUTPUT_FOLDER = os.path.join(os.path.dirname(__file__), "audio_output")
# Folder for logs of audio processing.
# Folder na logi przetwarzania audio.
AUDIO_LOG_FOLDER = os.path.join(os.path.dirname(__file__), "audio_logs")

# Create directories if they don't exist.
# Tworzy katalogi, jeśli nie istnieją.
os.makedirs(AUDIO_INPUT_FOLDER, exist_ok=True)
os.makedirs(AUDIO_OUTPUT_FOLDER, exist_ok=True)
os.makedirs(AUDIO_LOG_FOLDER, exist_ok=True)

# --- GEMINI API KEY CONFIGURATION ---
# --- KONFIGURACJA KLUCZA API GEMINI ---
# IMPORTANT: Replace "*****" with your real API key in config.yaml!
# WAŻNE: Zastąp "*****" swoim prawdziwym kluczem API w pliku config.yaml!
GEMINI_API_KEY = KEY
# Configure the Gemini API with the provided key.
# Konfiguruje API Gemini za pomocą podanego klucza.
genai.configure(api_key=GEMINI_API_KEY)
print("Gemini API configured successfully.")
print("Gemini API skonfigurowane pomyślnie.")


# --- Functions for Audio File Handling and Gemini Audio-to-Text ---
# --- Funkcje do obsługi plików audio i Gemini Audio-to-Text ---

def upload_audio_to_gemini_files_api(audio_file_path):
    # Print message indicating file upload.
    # Wyświetla komunikat o przesyłaniu pliku.
    print(f"Uploading audio file '{os.path.basename(audio_file_path)}' to Gemini Files API...")
    print(f"Przesyłanie pliku audio '{os.path.basename(audio_file_path)}' do Gemini Files API...")
    try:
        # Upload the file using genai.upload_file.
        # Przesyła plik za pomocą genai.upload_file.
        file = genai.upload_file(path=audio_file_path)
        print(f"File '{os.path.basename(audio_file_path)}' uploaded. Gemini File Name: {file.name}")
        print(f"Plik '{os.path.basename(audio_file_path)}' przesłany. Nazwa pliku Gemini: {file.name}")
        return file
    except Exception as e:
        # Error message if upload fails.
        # Komunikat o błędzie, jeśli przesłanie pliku się nie powiedzie.
        print(f"ERROR: Could not upload file '{audio_file_path}' to Gemini Files API: {e}")
        print(f"BŁĄD: Nie można przesłać pliku '{audio_file_path}' do Gemini Files API: {e}")
        return None


def transcribe_audio_with_gemini_model(audio_file_object, model_name, log_data):
    # Print message indicating audio transcription.
    # Wyświetla komunikat o transkrypcji audio.
    print(f"Transcribing audio using Gemini model '{model_name}'...")
    print(f"Transkrypcja audio za pomocą modelu Gemini '{model_name}'...")

    # Initialize the GenerativeModel.
    # Inicjuje model GenerativeModel.
    model = genai.GenerativeModel(model_name=model_name)

    # Prompt for transcription and stylistic/grammatical correction in Polish.
    # Prompt do transkrypcji i poprawy stylistycznej/gramatycznej w języku polskim.
    prompt_parts = [
        "Transcribe the audio recording into text. Return the text stylistically and grammatically corrected in Polish."
        "Przetranskrybuj nagranie audio na tekst. Zwróć tekst poprawiony stylistycznie i gramatycznie w języku polskim."
    ]

    # Count tokens for input (audio file and prompt).
    # Liczy tokeny dla inputu (pliku audio i promptu).
    try:
        # Note: count_tokens accepts a list of objects, including the audio_file_object and prompt part.
        # Uwaga: count_tokens przyjmuje listę obiektów, w tym audio_file_object i część promptu.
        count_response = model.count_tokens([audio_file_object, prompt_parts[0]])
        input_token_count = count_response.total_tokens
        print(f"Input token count: {input_token_count}")
        print(f"Liczba tokenów wejściowych: {input_token_count}")
        log_data["input_tokens"] = input_token_count
    except Exception as e:
        # Warning if input tokens cannot be counted.
        # Ostrzeżenie, jeśli nie można policzyć tokenów wejściowych.
        print(f"WARNING: Could not count input tokens: {e}")
        print(f"OSTRZEŻENIE: Nie można policzyć tokenów wejściowych: {e}")
        log_data["input_tokens"] = "ERROR"

    response_text = None
    try:
        # Pass the audio and prompt to generate_content.
        # Przekazuje audio i prompt do generate_content.
        response = model.generate_content([audio_file_object, prompt_parts[0]])
        response_text = response.text.strip()
        # Get output and total token counts from usage metadata.
        # Pobiera liczbę tokenów wyjściowych i całkowitą z metadanych użycia.
        log_data["output_tokens"] = response.usage_metadata.candidates_token_count if hasattr(response.usage_metadata,
                                                                                              'candidates_token_count') else "N/A"
        log_data["total_tokens"] = response.usage_metadata.total_token_count if hasattr(response.usage_metadata,
                                                                                        'total_token_count') else "N/A"
        print(f"Output token count: {log_data['output_tokens']}")
        print(f"Liczba tokenów wyjściowych: {log_data['output_tokens']}")
        print(f"Total tokens (input+output): {log_data['total_tokens']}")
        print(f"Łączna liczba tokenów (wejście+wyjście): {log_data['total_tokens']}")
        return response_text
    except Exception as e:
        # Error message if audio transcription/analysis fails.
        # Komunikat o błędzie, jeśli transkrypcja/analiza audio się nie powiedzie.
        print(f"ERROR: Could not transcribe/analyze audio with Gemini: {e}")
        print(f"BŁĄD: Nie można przetranskrybować/analizować audio z Gemini: {e}")
        log_data["error"] = str(e)
        return None


def delete_gemini_file(file_object):
    # Only proceed if file_object exists.
    # Kontynuuje tylko jeśli istnieje file_object.
    if file_object:
        # Print message indicating file deletion.
        # Wyświetla komunikat o usuwaniu pliku.
        print(f"Deleting file '{file_object.name}' from Gemini Files API...")
        print(f"Usuwanie pliku '{file_object.name}' z Gemini Files API...")
        try:
            # Delete the file from Gemini Files API.
            # Usuwa plik z Gemini Files API.
            genai.delete_file(file_object.name)
            print("File deleted successfully.")
            print("Plik usunięty pomyślnie.")
        except Exception as e:
            # Error message if deletion fails.
            # Komunikat o błędzie, jeśli usunięcie się nie powiedzie.
            print(f"ERROR: Could not delete file '{file_object.name}' from Gemini Files API: {e}")
            print(f"BŁĄD: Nie można usunąć pliku '{file_object.name}' z Gemini Files API: {e}")


def get_transcriber_function(transcriber_type="gemini_native"):
    # Check if the transcriber type is 'gemini_native'.
    # Sprawdza, czy typ transkrypcji to 'gemini_native'.
    if transcriber_type == "gemini_native":
        # Manually set the model to a more stable and proven one for audio.
        # Ręczne ustawienie modelu na bardziej stabilny i sprawdzony dla audio.
        supported_audio_model = "gemini-1.5-flash"

        print(f"Audio transcription model set to: {supported_audio_model}")
        print(f"Ustawiono model do transkrypcji audio na: {supported_audio_model}")

        # Define the inner function for Gemini native audio transcription.
        # Definiuje wewnętrzną funkcję do natywnej transkrypcji audio Gemini.
        def _transcribe_and_analyze_with_gemini_native(audio_file_path, log_data):
            # Upload the audio file to Gemini Files API.
            # Przesyła plik audio do Gemini Files API.
            file_obj = upload_audio_to_gemini_files_api(audio_file_path)
            if file_obj:
                log_data["gemini_file_name"] = file_obj.name
                try:
                    # Transcribe and analyze the audio using the Gemini model.
                    # Transkrybuje i analizuje audio za pomocą modelu Gemini.
                    analysis_text = transcribe_audio_with_gemini_model(file_obj, model_name=supported_audio_model,
                                                                       log_data=log_data)
                    return analysis_text
                finally:
                    # Ensure the file is deleted from Gemini Files API after processing.
                    # Upewnia się, że plik zostanie usunięty z Gemini Files API po przetworzeniu.
                    delete_gemini_file(file_obj)
            return None

        return _transcribe_and_analyze_with_gemini_native
    else:
        # Raise an error for an unknown transcriber type.
        # Podnosi błąd dla nieznanego typu transkrypcji.
        raise ValueError(f"Unknown transcription type: {transcriber_type}. Please choose 'gemini_native'.")
        raise ValueError(f"Nieznany typ transkrypcji: {transcriber_type}. Proszę wybrać 'gemini_native'.")


def process_audio_folder():
    print(f"\n--- Starting scan and processing of audio files from folder: {AUDIO_INPUT_FOLDER} ---")
    print(f"\n--- Rozpoczynam skanowanie i przetwarzanie plików audio z folderu: {AUDIO_INPUT_FOLDER} ---")

    # Supported audio file extensions.
    # Obsługiwane rozszerzenia plików audio.
    audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER)
                   if f.lower().endswith((".wav", ".mp3", ".m4a", ".flac"))]

    if not audio_files:
        print("INFO: No audio files found in the folder for analysis.")
        print("INFO: Brak plików audio w folderze do analizy.")
        return

    # Get the transcriber function.
    # Pobiera funkcję do transkrypcji.
    transcribe_and_analyze_function = get_transcriber_function("gemini_native")

    total_files_processed = 0
    total_tokens_used = 0
    total_processing_time = 0.0

    # Global list to collect logs for all files.
    # Globalna lista do zbierania logów dla wszystkich plików.
    overall_logs = []

    for audio_file in audio_files:
        audio_path = os.path.join(AUDIO_INPUT_FOLDER, audio_file)
        base_name = os.path.splitext(audio_file)[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_analysis_path = os.path.join(AUDIO_OUTPUT_FOLDER, f"{base_name}_analysis_{timestamp}.txt")
        log_file_path = os.path.join(AUDIO_LOG_FOLDER, f"{base_name}_log_{timestamp}.json")

        # Dictionary for logs of the current file.
        # Słownik na logi dla bieżącego pliku.
        current_log_data = {
            "timestamp": timestamp,
            "audio_file": audio_file,
            "status": "processing",
            "start_time_utc": datetime.datetime.utcnow().isoformat()
        }

        print(f"\n--- Processing file: {audio_file} ---")
        print(f"\n--- Przetwarzanie pliku: {audio_file} ---")
        file_start_time = time.time()

        analysis_result_text = None
        try:
            # Transcribe and analyze the audio file.
            # Transkrybuje i analizuje plik audio.
            analysis_result_text = transcribe_and_analyze_function(audio_path, current_log_data)

            if analysis_result_text:
                print(f"SUCCESS: Analysis of file '{audio_file}' completed.")
                print(f"SUKCES: Analiza pliku '{audio_file}' zakończona.")
                with open(output_analysis_path, "w", encoding="utf-8") as f:
                    f.write(analysis_result_text)
                print(f"Analysis result saved to: {output_analysis_path}")
                print(f"Wynik analizy zapisano do: {output_analysis_path}")
                current_log_data["status"] = "SUCCESS"
            else:
                print(f"WARNING: No analysis result for file '{audio_file}'.")
                print(f"OSTRZEŻENIE: Brak wyniku analizy dla pliku '{audio_file}'.")
                with open(output_analysis_path, "w", encoding="utf-8") as f:
                    f.write("[NO ANALYSIS RESULT FROM GEMINI]")
                    f.write("[BRAK WYNIKU ANALIZY Z GEMINI]")
                current_log_data["status"] = "WARNING_NO_RESULT"
        except Exception as e:
            print(f"ERROR: An error occurred while processing '{audio_file}': {e}")
            print(f"BŁĄD: Wystąpił błąd podczas przetwarzania '{audio_file}': {e}")
            with open(output_analysis_path, "w", encoding="utf-8") as f:
                f.write(f"[PROCESSING ERROR: {e}]")
                f.write(f"[BŁĄD PRZETWARZANIA: {e}]")
            current_log_data["status"] = "ERROR"
            current_log_data["exception_details"] = str(e)

        file_end_time = time.time()
        duration = file_end_time - file_start_time
        print(f"Processing time for '{audio_file}': {duration:.2f} seconds.")
        print(f"Czas przetwarzania dla '{audio_file}': {duration:.2f} sekundy.")

        current_log_data["duration_seconds"] = round(duration, 2)
        current_log_data["end_time_utc"] = datetime.datetime.utcnow().isoformat()

        # Save logs for the current file to a JSON file.
        # Zapisuje logi dla bieżącego pliku do pliku JSON.
        with open(log_file_path, "w", encoding="utf-8") as log_f:
            json.dump(current_log_data, log_f, indent=4, ensure_ascii=False)
        print(f"Logs for file '{audio_file}' saved to: {log_file_path}")
        print(f"Logi dla pliku '{audio_file}' zapisano do: {log_file_path}")

        overall_logs.append(current_log_data)

        total_files_processed += 1
        total_processing_time += duration
        # Check if total_tokens is an integer before adding.
        # Sprawdza, czy total_tokens jest liczbą całkowitą przed dodaniem.
        if "total_tokens" in current_log_data and isinstance(current_log_data["total_tokens"], int):
            total_tokens_used += current_log_data["total_tokens"]

    print(f"\n--- Finished processing all audio files. ---")
    print(f"\n--- Zakończono przetwarzanie wszystkich plików audio. ---")
    print(f"Total files processed: {total_files_processed}")
    print(f"Łącznie przetworzono plików: {total_files_processed}")
    print(f"Total execution time: {total_processing_time:.2f} seconds.")
    print(f"Całkowity czas działania: {total_processing_time:.2f} sekundy.")
    print(f"Total token usage for all files: {total_tokens_used} tokens.")
    print(f"Całkowite zużycie tokenów dla wszystkich plików: {total_tokens_used} tokenów.")

    # Optionally: Save a summary log for the entire session.
    # Opcjonalnie: Zapisz sumaryczny log dla całej sesji.
    summary_log_path = os.path.join(AUDIO_LOG_FOLDER,
                                    f"summary_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    summary_data = {
        "overall_summary": {
            "total_files_processed": total_files_processed,
            "total_processing_time_seconds": round(total_processing_time, 2),
            "total_tokens_used": total_tokens_used,
            "session_start_time_utc": overall_logs[0]["start_time_utc"] if overall_logs else "N/A",
            "session_end_time_utc": overall_logs[-1]["end_time_utc"] if overall_logs else "N/A"
        },
        "file_details": overall_logs
    }
    with open(summary_log_path, "w", encoding="utf-8") as sum_f:
        json.dump(summary_data, sum_f, indent=4, ensure_ascii=False)
    print(f"Session summary logs saved to: {summary_log_path}")
    print(f"Sumaryczne logi sesji zapisano do: {summary_log_path}")


if __name__ == "__main__":
    # Call the main function to process the audio folder.
    # Wywołuje główną funkcję do przetwarzania folderu z audio.
    process_audio_folder()
    print("\n--- Script audio-text.py execution finished. ---")
    print("\n--- Zakończono działanie skryptu audio-text.py ---")
--- END FILE: scripts/audio-text.py ---

--- START FILE: scripts/test.py ---
# --- Importing necessary libraries ---
# --- Importowanie niezbędnych bibliotek ---
# For filesystem operations like creating paths and folders. / Do operacji na systemie plików, jak tworzenie ścieżek i folderów.
import os
# For opening and extracting text from PDF files. / Do otwierania i wyciągania tekstu z plików PDF.
import pdfplumber
# For generating unique timestamps for filenames. / Do generowania unikalnych znaczników czasu dla nazw plików.
import datetime
# For loading configuration files in YAML format. / Do wczytywania plików konfiguracyjnych w formacie YAML.
import yaml
# For system interaction, e.g., to exit the script. / Do interakcji z systemem, np. do przerwania działania skryptu.
import sys
# For using regular expressions to fix line wrapping. / Do używania wyrażeń regularnych w celu naprawy zawijania wierszy.
import re
# For structured logging in JSON format. / Do strukturalnego logowania w formacie JSON.
import json
# For timing operations and pausing the script. / Do mierzenia czasu operacji i pauzowania skryptu.
import time
# The official Google library for interacting with the Gemini API. / Oficjalna biblioteka Google do interakcji z API Gemini.
import google.generativeai as genai
# For handling specific API errors like rate limiting. / Do obsługi specyficznych błędów API, takich jak limity zapytań.
from google.api_core import exceptions

# --- ReportLab imports for advanced PDF creation with paragraphs ---
# --- Importy ReportLab do zaawansowanego tworzenia PDF z akapitami ---
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib.enums import TA_JUSTIFY


# --- MAIN CONFIGURATION LOADING FUNCTION ---
# --- GŁÓWNA FUNKCJA ŁADUJĄCA KONFIGURACJĘ ---
def load_configuration(config_path='config.yaml'):
    """
    Loads configuration from a YAML file.
    Wczytuje konfigurację z pliku YAML.
    """
    try:
        with open(config_path, "r", encoding="utf-8") as cr:
            config = yaml.full_load(cr)

        if 'base_path' not in config:
            raise ValueError("Key 'base_path' is required.")
        if 'translator_script_config' not in config:
            raise ValueError("Section 'translator_script_config' is required.")
        if 'KEY' not in config or not config['KEY'] or config['KEY'] == "TWOJ_KLUCZ_API_GEMINI" or config[
            'KEY'] == "*****":
            raise ValueError("Gemini API Key ('KEY') is missing or is a placeholder.")

        base_path = config['base_path']
        translator_config = config['translator_script_config']

        conf = {
            "GEMINI_API_KEY": config['KEY'],
            "SOURCE_FOLDER": os.path.join(base_path, translator_config['source_folder']),
            "OUTPUT_FOLDER": os.path.join(base_path, translator_config['output_folder']),
            "LOG_FOLDER": os.path.join(base_path, translator_config.get('log_folder', 'LOGS')),
            "FONT_PATH": os.path.join(base_path, translator_config['font_path']),
            "FONT_NAME": translator_config['font_name'],
            "FONT_SIZE": translator_config.get('font_size', 10),
            "MODEL_NAME": translator_config.get('model_name', 'gemini-1.5-flash'),
            "CHUNK_SIZE_CHARS": translator_config.get('chunk_size_chars', 30000),
            "TARGET_LANGUAGES": translator_config.get('target_languages', ['English', 'Polish', 'Czech'])
        }
        print("Configuration loaded successfully.")
        print("Konfiguracja załadowana pomyślnie.")
        return conf
    except Exception as e:
        print(f"FATAL ERROR in configuration: {e}")
        print(f"BŁĄD KRYTYCZNY w konfiguracji: {e}")
        return None


# --- Initialization ---
# --- Inicjalizacja ---
CONFIG = load_configuration()
MODEL = None
if CONFIG:
    try:
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        genai.configure(api_key=CONFIG['GEMINI_API_KEY'])
        MODEL = genai.GenerativeModel(CONFIG['MODEL_NAME'], safety_settings=safety_settings)
        print("Gemini API configured successfully.")
        print("Gemini API skonfigurowane pomyślnie.")
    except Exception as e:
        CONFIG = None
    if CONFIG:
        os.makedirs(CONFIG['SOURCE_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['OUTPUT_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['LOG_FOLDER'], exist_ok=True)
        try:
            pdfmetrics.registerFont(TTFont(CONFIG['FONT_NAME'], CONFIG['FONT_PATH']))
            print(f"Font '{CONFIG['FONT_NAME']}' registered successfully.")
            print(f"Czcionka '{CONFIG['FONT_NAME']}' zarejestrowana pomyślnie.")
        except Exception as e:
            print(f"ERROR: Could not register font. Defaulting to Helvetica. Error: {e}")
            print(f"BŁĄD: Nie można zarejestrować czcionki. Używam domyślnej Helvetica. Błąd: {e}")
            CONFIG['FONT_NAME'] = "Helvetica"
else:
    print("Exiting script due to configuration errors.")
    print("Zamykanie skryptu z powodu błędów konfiguracji.")
    sys.exit(1)


# --- Core Functions ---
# --- Główne Funkcje ---

def extract_full_text_from_pdf(pdf_path):
    """
    Extracts all text from a PDF file into a single string.
    Ekstrahuje cały tekst z pliku PDF do jednego ciągu znaków.
    """
    print(f"Extracting full text from '{os.path.basename(pdf_path)}'...")
    print(f"Ekstrahuję pełny tekst z '{os.path.basename(pdf_path)}'...")
    full_text = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    full_text.append(page_text)
        return "\n\n".join(full_text)
    except Exception as e:
        print(f"ERROR: Could not read PDF file {pdf_path}: {e}")
        print(f"BŁĄD: Nie można odczytać pliku PDF {pdf_path}: {e}")
        return None


def chunk_text(text, chunk_size):
    """
    Splits a large text into smaller chunks based on a character size limit.
    Dzieli duży tekst na mniejsze kawałki na podstawie limitu znaków.
    """
    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]


def translate_text_in_chunks(text_to_translate, target_language):
    """
    Translates text, handles rate limits and overloads by retrying, and manages other safety blocks.
    Tłumaczy tekst, obsługuje limity i przeciążenia poprzez ponawianie prób i zarządza innymi blokadami.
    """
    if not text_to_translate or not text_to_translate.strip():
        return "", 0, 0

    chunks = chunk_text(text_to_translate, CONFIG['CHUNK_SIZE_CHARS'])
    print(f"Text divided into {len(chunks)} chunk(s) for translation to {target_language}.")
    print(f"Tekst podzielony na {len(chunks)} części do tłumaczenia na {target_language}.")

    translated_parts = []
    total_input_tokens = 0
    total_output_tokens = 0

    base_prompt = f"You are a professional translator. Translate the following document fragment into {target_language}. Preserve the original formatting, including paragraph breaks. Return only the translated text, without any additional comments, explanations or introductions."

    for i, chunk in enumerate(chunks):
        print(f"  Translating chunk {i + 1}/{len(chunks)}...")
        print(f"  Tłumaczę część {i + 1}/{len(chunks)}...")
        prompt = f"{base_prompt}\n\nFragment to translate:\n\n{chunk}"

        max_retries = 5
        current_retry = 0
        delay = 15

        while current_retry < max_retries:
            try:
                response = MODEL.generate_content(prompt)

                if not response.parts:
                    block_reason = response.prompt_feedback.block_reason.name if response.prompt_feedback else "UNKNOWN"
                    print(
                        f"  WARNING: Chunk {i + 1} translation blocked by API. Reason: {block_reason}. Inserting original text.")
                    print(
                        f"  OSTRZEŻENIE: Tłumaczenie fragmentu {i + 1} zablokowane przez API. Powód: {block_reason}. Wstawiam oryginalny tekst.")
                    warning_msg = f"[API TRANSLATION BLOCKED (REASON: {block_reason}) - ORIGINAL TEXT INSERTED BELOW]"
                    translated_parts.append(f"\n\n--- {warning_msg} ---\n\n{chunk}\n\n")
                    break

                translated_parts.append(response.text)
                if hasattr(response, 'usage_metadata'):
                    total_input_tokens += response.usage_metadata.prompt_token_count
                    total_output_tokens += response.usage_metadata.candidates_token_count
                break

            except (exceptions.ResourceExhausted, exceptions.ServiceUnavailable, exceptions.DeadlineExceeded) as e:
                current_retry += 1
                error_type = type(e).__name__
                if current_retry >= max_retries:
                    print(f"  ERROR: Max retries exceeded for chunk. Error: {error_type}. Inserting original text.")
                    print(
                        f"  BŁĄD: Przekroczono maksymalną liczbę prób dla fragmentu. Błąd: {error_type}. Wstawiam oryginalny tekst.")
                    translated_parts.append(
                        f"\n\n[TRANSLATION FAILED AFTER RETRIES: {error_type}] - ORIGINAL TEXT INSERTED BELOW\n\n{chunk}\n\n")
                    break

                print(
                    f"  API temporary error ({error_type}). Retrying in {delay} seconds... (Attempt {current_retry}/{max_retries})")
                print(
                    f"  Tymczasowy błąd API ({error_type}). Ponawiam próbę za {delay} sekund... (Próba {current_retry}/{max_retries})")
                time.sleep(delay)
                delay *= 2

            except Exception as e:
                print(f"  An unexpected API error occurred: {e}. Inserting original text.")
                print(f"  Wystąpił nieoczekiwany błąd API: {e}. Wstawiam oryginalny tekst.")
                translated_parts.append(
                    f"\n\n[UNEXPECTED TRANSLATION ERROR: {e}] - ORIGINAL TEXT INSERTED BELOW\n\n{chunk}\n\n")
                break

        time.sleep(1)

    print(f"Token Usage for {target_language}: Input={total_input_tokens}, Output={total_output_tokens}")
    print(f"Zużycie tokenów dla {target_language}: Wejście={total_input_tokens}, Wyjście={total_output_tokens}")
    return "\n\n".join(translated_parts), total_input_tokens, total_output_tokens


def reflow_text(text: str) -> str:
    """
    Intelligently joins lines for better PDF formatting.
    Inteligentnie łączy linie dla lepszego formatowania PDF.
    """
    reflowed = re.sub(r'(?<!\n)\n(?!\n)', ' ', text)
    reflowed = re.sub(r'\n{2,}', '<br/><br/>', reflowed)
    return reflowed


def save_text_to_pdf(text_content, output_pdf_path):
    """
    Saves the given text content to a PDF file using Platypus for proper text wrapping.
    Zapisuje podany tekst do pliku PDF, używając biblioteki Platypus do poprawnego zawijania tekstu.
    """
    font_name, font_size = CONFIG['FONT_NAME'], CONFIG['FONT_SIZE']
    print(f"Saving PDF to: {output_pdf_path}...")
    print(f"Zapisuję PDF do: {output_pdf_path}...")

    doc = SimpleDocTemplate(output_pdf_path, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)
    styles = getSampleStyleSheet()
    style = ParagraphStyle(name='Normal_Justified', parent=styles['Normal'], fontName=font_name, fontSize=font_size,
                           leading=font_size * 1.5, alignment=TA_JUSTIFY)

    processed_text = reflow_text(text_content)
    story = [Paragraph(processed_text, style)]

    try:
        doc.build(story)
        print(f"Successfully saved PDF: {output_pdf_path}")
        print(f"Pomyślnie zapisano PDF: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR saving PDF: {e}")
        print(f"BŁĄD podczas zapisywania PDF: {e}")


# --- Main Execution ---
# --- Główne Wykonanie ---
def main():
    """
    Main function to find, translate, and save PDFs into separate files per language.
    Główna funkcja do znajdowania, tłumaczenia i zapisywania plików PDF w osobnych plikach dla każdego języka.
    """
    print(f"Starting PDF translation from folder: {CONFIG['SOURCE_FOLDER']}")
    print(f"Rozpoczynam tłumaczenie PDF z folderu: {CONFIG['SOURCE_FOLDER']}")

    pdf_files = sorted([f for f in os.listdir(CONFIG['SOURCE_FOLDER']) if f.lower().endswith(".pdf")])

    if not pdf_files:
        print("INFO: No PDF files found in the source folder for translation.")
        print("INFO: Brak plików PDF w folderze źródłowym do tłumaczenia.")
        return

    for pdf_file in pdf_files:
        print(f"\n--- Processing file: {pdf_file} ---")
        print(f"--- Przetwarzam plik: {pdf_file} ---")

        pdf_path = os.path.join(CONFIG['SOURCE_FOLDER'], pdf_file)
        original_text = extract_full_text_from_pdf(pdf_path)

        if not original_text:
            print(f"WARNING: No text extracted from '{pdf_file}'. Skipping.")
            print(f"OSTRZEŻENIE: Nie wyekstrahowano tekstu z '{pdf_file}'. Pomijam.")
            continue

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.splitext(pdf_file)[0]

        # Mapping language names to file suffixes, sorted alphabetically by language name.
        # Mapowanie nazw języków na przyrostki plików, posortowane alfabetycznie według nazwy języka.
        lang_suffix_map = {
            "english": "EN",
            "polish": "PL",
            "czech": "CS",
            "ukrainian": "UA",
            "german": "DE",
            "french": "FR",
            "spanish": "ES",
            "russian": "RU",
            "arabic": "AR",
            "chinese": "ZH",
            "hebrew": "HE",
            "japanese": "JA",
            "persian": "FA",
        }

        for lang in CONFIG.get('TARGET_LANGUAGES', ['English', 'Polish']):
            print(f"\n--- Starting translation for {lang} ---")
            print(f"--- Rozpoczynam tłumaczenie na {lang} ---")

            translated_text, _, _ = translate_text_in_chunks(original_text, lang)

            if translated_text:
                lang_lower = lang.lower()
                lang_suffix = lang_suffix_map.get(lang_lower, lang_lower[:2].upper())
                output_path = os.path.join(CONFIG['OUTPUT_FOLDER'], f"{base_name}_{timestamp}_{lang_suffix}.pdf")

                save_text_to_pdf(translated_text, output_path)
            else:
                print(f"WARNING: Translation for {lang} resulted in empty text. No file will be saved.")
                print(f"OSTRZEŻENIE: Tłumaczenie na {lang} zwróciło pusty tekst. Plik nie zostanie zapisany.")

            sleep_duration = 20
            print(
                f"--- Finished {lang}. Waiting for {sleep_duration} seconds before next language to manage rate limits... ---")
            print(
                f"--- Ukończono {lang}. Czekam {sleep_duration} sekund przed kolejnym językiem w celu zarządzania limitami... ---")
            time.sleep(sleep_duration)

    print("\n--- Finished translation process for all files. ---")
    print("\n--- Zakończono proces tłumaczenia dla wszystkich plików. ---")


if __name__ == "__main__":
    if CONFIG:
        main()
--- END FILE: scripts/test.py ---

--- START FILE: scripts/config.yaml ---
# --- API Key Configuration ---
# --- Konfiguracja Klucza API ---
KEY: "*****" # <-- Wklej tutaj swój prawdziwy klucz / Paste your real key here

# --- Main Project Configuration ---
# --- Główna Konfiguracja Projektu ---
# The main, absolute path to the project directory. All other paths will be built based on this one.
# Główna, absolutna ścieżka do katalogu projektu. Wszystkie inne ścieżki będą budowane na jej podstawie.
base_path: "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI"

# --- RAG Pipeline Configuration (Updated for 2-DB Architecture) ---
# --- Konfiguracja Potoku RAG (Zaktualizowana dla Architektury 2 Baz) ---
rag_pipeline_config:
  # Source folders for the two types of corpora
  # Foldery źródłowe dla dwóch typów korpusów
  legal_source_folder: "TEMP/LAW"
  case_source_folder: "TEMP/CASE_DOCS"

  # Vector Database folders for each corpus
  # Foldery baz wektorowych dla każdego korpusu
  vector_db_legal_folder: "KNOWLEDGE_BASE/VECTOR_DB_LEGAL"
  vector_db_case_folder: "KNOWLEDGE_BASE/VECTOR_DB_CASE"

  # Folder for log files generated by the RAG scripts
  # Folder na pliki logów generowane przez skrypty RAG
  log_folder: "LOGS"

  # Model used for creating vector embeddings
  # Model używany do tworzenia wektorów (embeddings)
  embedding_model: "models/text-embedding-004"

  # Large Language Model used for generating answers
  # Duży Model Językowy używany do generowania odpowiedzi
  llm_model: "gemini-1.5-flash"

# --- Configuration for the Content Merging Script ---
# --- Konfiguracja dla Skryptu Łączącego Treści ---
merger_script_config:
  source_folder: "TEMP"
  output_folder: "FOR_ANALYSIS"
  font_path: "UbuntuMono-Regular.ttf"
  font_name: "UbuntuMono"
  font_size: 12
  model_name: "gemini-1.5-flash"
  ocr_prompt: "GEMINI, Make OCR. Do not add any additional information, just the text."
  audio_prompt: "Transcribe the audio recording. Correct the text for grammar and style, returning only the final, clean text in Polish."
  ocr_resolution: 150

# --- Configuration for the Translation Script ---
# --- Konfiguracja dla Skryptu Tłumaczącego ---
translator_script_config:
  source_folder: "FOR_ANALYSIS"
  output_folder: "TRANSLATIONS"
  font_path: "UbuntuMono-Regular.ttf"
  font_name: "UbuntuMono"
  font_size: 12
  model_name: "gemini-1.5-flash"
  chunk_size_chars: 30000

  # List of target languages for translation
  # Lista języków docelowych dla tłumaczenia
  target_languages:
    - "English"
    - "Polish"
    #- "Arabic"
    #- "Chinese"
    #- "Czech"
    #- "French"
    #- "German"
    #- "Hebrew"
    #- "Japanese"
    #- "Persian"
    #- "Russian"
    #- "Spanish"
    #- "Ukrainian"

# --- Configuration for Other Scripts (e.g., Google Drive Upload) ---
# --- Konfiguracja dla Innych Skryptów (np. Przesyłanie na Dysk Google) ---
folders_to_check:
  #- image_output
  #- TRANSLATIONS
  #- audio_input
  #- FOR_ANALYSIS
  #- LOGS
  #- audio_logs
  #- image_input
  #- PROCESSED_OUTPUT
  #- audio_output
  #- image_logs
  #- TEMP
  #- KNOWLEDGE_BASE

# Parent folder ID on Google Drive, used by the upload script
# ID folderu nadrzędnego na Dysku Google, używane przez skrypt do przesyłania plików
google_drive_parent_folder_id: "*****"
--- END FILE: scripts/config.yaml ---

--- START FILE: scripts/image-text.py ---
import os
import google.generativeai as genai
import datetime
import time
import json
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import yaml

with open("config.yaml", "r") as cr:
    config_vals = yaml.full_load(cr)
KEY = config_vals['KEY']

# --- PATH CONFIGURATION ---
# --- KONFIGURACJA ŚCIEŻEK ---
# Folder for input images.
# Folder na obrazy wejściowe.
IMAGE_INPUT_FOLDER = os.path.join(os.path.dirname(__file__), "image_input")
# Folder for output analysis results.
# Folder na wyniki analizy.
IMAGE_OUTPUT_FOLDER = os.path.join(os.path.dirname(__file__), "image_output")
# Folder for logs of image processing.
# Folder na logi przetwarzania obrazów.
IMAGE_LOG_FOLDER = os.path.join(os.path.dirname(__file__), "image_logs")

# Define the path to the Ubuntu Mono font file.
# Make sure 'UbuntuMono-R.ttf' is in the same directory as this script, or provide a full path.
# Zdefiniuj ścieżkę do pliku czcionki Ubuntu Mono.
# Upewnij się, że 'UbuntuMono-R.ttf' znajduje się w tym samym katalogu co ten skrypt, lub podaj pełną ścieżkę.
UBUNTU_MONO_FONT_PATH = os.path.join(os.path.dirname(__file__), "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/UbuntuMono-Regular.ttf")

# Create directories if they don't exist.
# Tworzy katalogi, jeśli nie istnieją.
os.makedirs(IMAGE_INPUT_FOLDER, exist_ok=True)
os.makedirs(IMAGE_OUTPUT_FOLDER, exist_ok=True)
os.makedirs(IMAGE_LOG_FOLDER, exist_ok=True)

# Register the Ubuntu Mono font with ReportLab.
# Zarejestruj czcionkę Ubuntu Mono w ReportLab.
try:
    pdfmetrics.registerFont(TTFont('UbuntuMono', UBUNTU_MONO_FONT_PATH))
    print(f"Font 'UbuntuMono' registered successfully from {UBUNTU_MONO_FONT_PATH}.")
    print(f"Czcionka 'UbuntuMono' zarejestrowana pomyślnie z {UBUNTU_MONO_FONT_PATH}.")
except Exception as e:
    print(
        f"ERROR: Could not register Ubuntu Mono font from {UBUNTU_MONO_FONT_PATH}. Please ensure the file exists and is accessible. Error: {e}")
    print(
        f"BŁĄD: Nie można zarejestrować czcionki Ubuntu Mono z {UBUNTU_MONO_FONT_PATH}. Upewnij się, że plik istnieje i jest dostępny. Błąd: {e}")
    # Fallback to a default font if Ubuntu Mono cannot be registered.
    # W razie problemów z rejestracją, użyj domyślnej czcionki.
    DEFAULT_FONT = "Helvetica"
else:
    DEFAULT_FONT = "UbuntuMono"

FONT_SIZE = 12  # Font size for the PDF output / Rozmiar czcionki dla wyjścia PDF

# --- GEMINI API KEY CONFIGURATION ---
# --- KONFIGURACJA KLUCZA API GEMINI ---
# IMPORTANT: Replace "*****" with your real API key in config.yaml!
# WAŻNE: Zastąp "*****" swoim prawdziwym kluczem API w pliku config.yaml!
GEMINI_API_KEY = KEY
# Configure the Gemini API with the provided key.
# Konfiguruje API Gemini za pomocą podanego klucza.
genai.configure(api_key=GEMINI_API_KEY)
print("Gemini API configured successfully.")
print("Gemini API skonfigurowane pomyślnie.")


# --- Functions for Image File Handling and Gemini Vision ---
# --- Funkcje do obsługi plików graficznych i Gemini Vision ---

def upload_image_to_gemini_files_api(image_file_path):
    # Print message indicating file upload.
    # Wyświetla komunikat o przesyłaniu pliku.
    print(f"Uploading image file '{os.path.basename(image_file_path)}' to Gemini Files API...")
    print(f"Przesyłanie pliku graficznego '{os.path.basename(image_file_path)}' do Gemini Files API...")
    try:
        # Upload the file using genai.upload_file.
        # Przesyła plik za pomocą genai.upload_file.
        file = genai.upload_file(path=image_file_path)
        print(f"File '{os.path.basename(image_file_path)}' uploaded. Gemini File Name: {file.name}")
        print(f"Plik '{os.path.basename(image_file_path)}' przesłany. Nazwa pliku Gemini: {file.name}")
        return file
    except Exception as e:
        # Error message if upload fails.
        # Komunikat o błędzie, jeśli przesłanie pliku się nie powiedzie.
        print(f"ERROR: Could not upload file '{image_file_path}' to Gemini Files API: {e}")
        print(f"BŁĄD: Nie można przesłać pliku '{image_file_path}' do Gemini Files API: {e}")
        return None


def analyze_image_with_gemini_model(image_file_object, model_name, prompt, log_data):
    # Print message indicating image analysis.
    # Wyświetla komunikat o analizie obrazu.
    print(f"Analyzing image with Gemini model '{model_name}'...")
    print(f"Analiza obrazu za pomocą modelu Gemini '{model_name}'...")

    # Initialize the GenerativeModel.
    # Inicjuje model GenerativeModel.
    model = genai.GenerativeModel(model_name=model_name)

    # Count tokens for input (image file and prompt).
    # Liczy tokeny dla inputu (pliku graficznego i promptu).
    try:
        # Note: For images, 'count_tokens' accepts a list of objects, including the image_file_object.
        # Uwaga: Dla obrazów 'count_tokens' przyjmuje listę obiektów, w tym image_file_object.
        count_response = model.count_tokens([image_file_object, prompt])
        input_token_count = count_response.total_tokens
        print(f"Input token count: {input_token_count}")
        print(f"Liczba tokenów wejściowych: {input_token_count}")
        log_data["input_tokens"] = input_token_count
    except Exception as e:
        # Warning if input tokens cannot be counted.
        # Ostrzeżenie, jeśli nie można policzyć tokenów wejściowych.
        print(f"WARNING: Could not count input tokens: {e}")
        print(f"OSTRZEŻENIE: Nie można policzyć tokenów wejściowych: {e}")
        log_data["input_tokens"] = "ERROR"

    response_text = None
    try:
        # Pass the image and prompt to generate_content.
        # Przekazuje obraz i prompt do generate_content.
        response = model.generate_content([image_file_object, prompt])
        response_text = response.text.strip()
        # Get output and total token counts from usage metadata.
        # Pobiera liczbę tokenów wyjściowych i całkowitą z metadanych użycia.
        log_data["output_tokens"] = response.usage_metadata.candidates_token_count if hasattr(response.usage_metadata,
                                                                                              'candidates_token_count') else "N/A"
        log_data["total_tokens"] = response.usage_metadata.total_token_count if hasattr(response.usage_metadata,
                                                                                        'total_token_count') else "N/A"
        print(f"Output token count: {log_data['output_tokens']}")
        print(f"Liczba tokenów wyjściowych: {log_data['output_tokens']}")
        print(f"Total tokens (input+output): {log_data['total_tokens']}")
        print(f"Łączna liczba tokenów (wejście+wyjście): {log_data['total_tokens']}")
        return response_text
    except Exception as e:
        # Error message if image analysis fails.
        # Komunikat o błędzie, jeśli analiza obrazu się nie powiedzie.
        print(f"ERROR: Could not analyze image with Gemini: {e}")
        print(f"BŁĄD: Nie można analizować obrazu z Gemini: {e}")
        log_data["error"] = str(e)
        return None


def delete_gemini_file(file_object):
    # Only proceed if file_object exists.
    # Kontynuuje tylko jeśli istnieje file_object.
    if file_object:
        # Print message indicating file deletion.
        # Wyświetla komunikat o usuwaniu pliku.
        print(f"Deleting file '{file_object.name}' from Gemini Files API...")
        print(f"Usuwanie pliku '{file_object.name}' z Gemini Files API...")
        try:
            # Delete the file from Gemini Files API.
            # Usuwa plik z Gemini Files API.
            genai.delete_file(file_object.name)
            print("File deleted successfully.")
            print("Plik usunięty pomyślnie.")
        except Exception as e:
            # Error message if deletion fails.
            # Komunikat o błędzie, jeśli usunięcie się nie powiedzie.
            print(f"ERROR: Could not delete file '{file_object.name}' from Gemini Files API: {e}")
            print(f"BŁĄD: Nie można usunąć pliku '{file_object.name}' z Gemini Files API: {e}")


def get_image_analyzer_function(analyzer_type="gemini_native"):
    # Check if the analyzer type is 'gemini_native'.
    # Sprawdza, czy typ analizatora to 'gemini_native'.
    if analyzer_type == "gemini_native":
        # Model for image analysis (multimodal).
        # Model do analizy obrazów (multimodalny).
        # Use "gemini-1.5-flash" or "gemini-1.5-pro" for more advanced analysis.
        # Użyj "gemini-1.5-flash" lub "gemini-1.5-pro" dla bardziej zaawansowanych analiz.
        supported_image_model = "gemini-1.5-flash"

        print(f"Image analysis model set to: {supported_image_model}")
        print(f"Ustawiono model do analizy obrazów na: {supported_image_model}")

        # Define the inner function for Gemini native image analysis.
        # Definiuje wewnętrzną funkcję do natywnej analizy obrazów Gemini.
        def _analyze_image_with_gemini_native(image_file_path, prompt_for_image, log_data):
            # Upload the image to Gemini Files API.
            # Przesyła obraz do Gemini Files API.
            file_obj = upload_image_to_gemini_files_api(image_file_path)
            if file_obj:
                log_data["gemini_file_name"] = file_obj.name
                try:
                    # Analyze the image using the Gemini model.
                    # Analizuje obraz za pomocą modelu Gemini.
                    analysis_text = analyze_image_with_gemini_model(file_obj,
                                                                    model_name=supported_image_model,
                                                                    prompt=prompt_for_image,
                                                                    log_data=log_data)
                    return analysis_text
                finally:
                    # Ensure the file is deleted from Gemini Files API after analysis.
                    # Upewnia się, że plik zostanie usunięty z Gemini Files API po analizie.
                    delete_gemini_file(file_obj)
            return None

        return _analyze_image_with_gemini_native
    else:
        # Raise an error for an unknown analyzer type.
        # Podnosi błąd dla nieznanego typu analizatora.
        raise ValueError(f"Unknown image analysis type: {analyzer_type}. Please choose 'gemini_native'.")
        raise ValueError(f"Nieznany typ analizy obrazu: {analyzer_type}. Proszę wybrać 'gemini_native'.")


# --- New function to save text to PDF ---
# --- Nowa funkcja do zapisywania tekstu do PDF ---
def save_text_to_pdf(text_content, output_pdf_path, font_name, font_size):
    print(f"Saving text to PDF: {output_pdf_path} with font '{font_name}' {font_size}pt...")
    print(f"Zapisywanie tekstu do PDF: {output_pdf_path} czcionką '{font_name}' {font_size}pkt...")
    try:
        c = canvas.Canvas(output_pdf_path, pagesize=A4)
        c.setFont(font_name, font_size)
        width, height = A4

        # Margins / Marginesy
        left_margin = 50
        top_margin = height - 50
        line_height = font_size * 1.2  # Adjust for spacing / Dostosuj do odstępów

        y_position = top_margin

        # Split text into lines, handling long lines
        # Podziel tekst na linie, obsługując długie linie
        lines = []
        for paragraph in text_content.split('\n'):
            wrapped_lines = []
            if paragraph.strip():  # Avoid processing empty paragraphs
                # Calculate max characters per line for the given font and size
                # Oblicz maksymalną liczbę znaków na linię dla danej czcionki i rozmiaru
                char_width = pdfmetrics.stringWidth('M', font_name, font_size)  # Width of a typical character
                max_chars_per_line = int((width - 2 * left_margin) / char_width) if char_width > 0 else 100

                # ReportLab's textobject handles wrapping better for monospaced fonts,
                # but a manual wrap ensures we control chunking.
                # Obiekt tekstowy ReportLab lepiej obsługuje zawijanie dla czcionek monospaced,
                # ale ręczne zawijanie zapewnia kontrolę nad chunkowaniem.
                current_line = ""
                for word in paragraph.split(' '):
                    if pdfmetrics.stringWidth(current_line + (word + ' '), font_name, font_size) < (
                            width - 2 * left_margin):
                        current_line += (word + ' ')
                    else:
                        wrapped_lines.append(current_line.strip())
                        current_line = word + ' '
                if current_line.strip():
                    wrapped_lines.append(current_line.strip())
            else:
                wrapped_lines.append("")  # Keep empty lines for paragraph breaks
            lines.extend(wrapped_lines)

        for line in lines:
            if y_position < 50:  # Check if new page is needed (50 is bottom margin)
                c.showPage()
                c.setFont(font_name, font_size)
                y_position = top_margin

            c.drawString(left_margin, y_position, line)
            y_position -= line_height

        c.save()
        print(f"Successfully saved PDF to: {output_pdf_path}")
        print(f"Pomyślnie zapisano PDF do: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR: Could not save text to PDF '{output_pdf_path}': {e}")
        print(f"BŁĄD: Nie można zapisać tekstu do PDF '{output_pdf_path}': {e}")


def process_image_folder():
    print(f"\n--- Starting scan and processing of image files from folder: {IMAGE_INPUT_FOLDER} ---")
    print(f"\n--- Rozpoczynam skanowanie i przetwarzanie plików graficznych z folderu: {IMAGE_INPUT_FOLDER} ---")

    # Supported image file extensions.
    # Obsługiwane rozszerzenia plików graficznych.
    image_files = [f for f in os.listdir(IMAGE_INPUT_FOLDER)
                   if f.lower().endswith((".png", ".jpg", ".jpeg", ".webp", ".pdf"))]

    if not image_files:
        print("INFO: No image files found in the folder for analysis.")
        print("INFO: Brak plików graficznych w folderze do analizy.")
        return

    # You can define a single prompt for all images or customize it for each.
    # Możesz zdefiniować pojedynczy prompt dla wszystkich obrazów lub dostosować go dla każdego z osobna.
    # Example of a simple prompt:
    # Przykład prostego promptu:
    default_image_prompt = "GEMINI, Make OCR, And Make Output in Polish and English Language. Do not add any additional information, just the text."  # "Describe in detail what you see in the image. Indicate the most important elements, colors, text (if present), and the general mood or context."
    # default_image_prompt = "Opisz szczegółowo co widzisz na obrazie. Wskaż najważniejsze elementy, kolory, tekst (jeśli występuje) oraz ogólny nastrój lub kontekst."

    # Example of a more advanced prompt (if you want to analyze documents, for example):
    # Przykład bardziej zaawansowanego promptu (jeśli chcesz analizować np. dokumenty):
    # default_image_prompt = "Transcribe all visible text in the image. Then, summarize the main content of the document and indicate if it contains any dates or key data."
    # default_image_prompt = "Przetranskrybuj cały tekst widoczny na obrazie. Następnie, podsumuj główną treść dokumentu i wskaż, czy zawiera jakiekolwiek daty lub kluczowe dane."

    # Get the image analyzer function.
    # Pobiera funkcję analizującą obrazy.
    analyze_image_function = get_image_analyzer_function("gemini_native")

    total_files_processed = 0
    total_tokens_used = 0
    total_processing_time = 0.0

    # Global list to collect logs for all files.
    # Globalna lista do zbierania logów dla wszystkich plików.
    overall_logs = []

    for image_file in image_files:
        image_path = os.path.join(IMAGE_INPUT_FOLDER, image_file)
        base_name = os.path.splitext(image_file)[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_txt_path = os.path.join(IMAGE_OUTPUT_FOLDER, f"{base_name}_analysis_{timestamp}.txt")
        output_pdf_path = os.path.join(IMAGE_OUTPUT_FOLDER, f"{base_name}_analysis_{timestamp}.pdf")  # New PDF path
        log_file_path = os.path.join(IMAGE_LOG_FOLDER, f"{base_name}_log_{timestamp}.json")

        # Dictionary for logs of the current file.
        # Słownik na logi dla bieżącego pliku.
        current_log_data = {
            "timestamp": timestamp,
            "image_file": image_file,
            "status": "processing",
            "start_time_utc": datetime.datetime.utcnow().isoformat()
        }

        print(f"\n--- Processing file: {image_file} ---")
        print(f"\n--- Przetwarzanie pliku: {image_file} ---")
        file_start_time = time.time()

        analysis_result_text = None
        try:
            # Pass the prompt to the image analysis function.
            # Przekazuje prompt do funkcji analizującej obraz.
            analysis_result_text = analyze_image_function(image_path, default_image_prompt, current_log_data)

            if analysis_result_text:
                print(f"SUCCESS: Analysis of file '{image_file}' completed.")
                print(f"SUKCES: Analiza pliku '{image_file}' zakończona.")

                # Save to TXT
                # Zapisz do TXT
                with open(output_txt_path, "w", encoding="utf-8") as f:
                    f.write(analysis_result_text)
                print(f"Analysis result saved to TXT: {output_txt_path}")
                print(f"Wynik analizy zapisano do TXT: {output_txt_path}")

                # Save to PDF
                # Zapisz do PDF
                save_text_to_pdf(analysis_result_text, output_pdf_path, DEFAULT_FONT, FONT_SIZE)

                current_log_data["status"] = "SUCCESS"
            else:
                print(f"WARNING: No analysis result for file '{image_file}'.")
                print(f"OSTRZEŻENIE: Brak wyniku analizy dla pliku '{image_file}'.")
                with open(output_txt_path, "w", encoding="utf-8") as f:
                    f.write("[NO ANALYSIS RESULT FROM GEMINI]")
                    f.write("[BRAK WYNIKU ANALIZY Z GEMINI]")
                # Optionally create an empty or warning PDF
                # Opcjonalnie stwórz pusty lub ostrzegawczy PDF
                save_text_to_pdf("[NO ANALYSIS RESULT FROM GEMINI]\n[BRAK WYNIKU ANALIZY Z GEMINI]", output_pdf_path,
                                 DEFAULT_FONT, FONT_SIZE)
                current_log_data["status"] = "WARNING_NO_RESULT"
        except Exception as e:
            print(f"ERROR: An error occurred while processing '{image_file}': {e}")
            print(f"BŁĄD: Wystąpił błąd podczas przetwarzania '{image_file}': {e}")
            with open(output_txt_path, "w", encoding="utf-8") as f:
                f.write(f"[PROCESSING ERROR: {e}]")
                f.write(f"[BŁĄD PRZETWARZANIA: {e}]")
            # Optionally create an error PDF
            # Opcjonalnie stwórz PDF z błędem
            save_text_to_pdf(f"[PROCESSING ERROR: {e}]\n[BŁĄD PRZETWARZANIA: {e}]", output_pdf_path, DEFAULT_FONT,
                             FONT_SIZE)
            current_log_data["status"] = "ERROR"
            current_log_data["exception_details"] = str(e)

        file_end_time = time.time()
        duration = file_end_time - file_start_time
        print(f"Processing time for '{image_file}': {duration:.2f} seconds.")
        print(f"Czas przetwarzania dla '{image_file}': {duration:.2f} sekundy.")

        current_log_data["duration_seconds"] = round(duration, 2)
        current_log_data["end_time_utc"] = datetime.datetime.utcnow().isoformat()

        # Save logs for the current file to a JSON file.
        # Zapisuje logi dla bieżącego pliku do pliku JSON.
        with open(log_file_path, "w", encoding="utf-8") as log_f:
            json.dump(current_log_data, log_f, indent=4, ensure_ascii=False)
        print(f"Logs for file '{image_file}' saved to: {log_file_path}")
        print(f"Logi dla pliku '{image_file}' zapisano do: {log_file_path}")

        overall_logs.append(current_log_data)

        total_files_processed += 1
        total_processing_time += duration
        # Check if total_tokens is an integer before adding.
        # Sprawdza, czy total_tokens jest liczbą całkowitą przed dodaniem.
        if "total_tokens" in current_log_data and isinstance(current_log_data["total_tokens"], int):
            total_tokens_used += current_log_data["total_tokens"]

    print(f"\n--- Finished processing all image files. ---")
    print(f"\n--- Zakończono przetwarzanie wszystkich plików graficznych. ---")
    print(f"Total files processed: {total_files_processed}")
    print(f"Łącznie przetworzono plików: {total_files_processed}")
    print(f"Total execution time: {total_processing_time:.2f} seconds.")
    print(f"Całkowity czas działania: {total_processing_time:.2f} sekundy.")
    print(f"Total token usage for all files: {total_tokens_used} tokens.")
    print(f"Całkowite zużycie tokenów dla wszystkich plików: {total_tokens_used} tokenów.")

    # Optionally: Save a summary log for the entire session.
    # Opcjonalnie: Zapisz sumaryczny log dla całej sesji.
    summary_log_path = os.path.join(IMAGE_LOG_FOLDER,
                                    f"summary_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    summary_data = {
        "overall_summary": {
            "total_files_processed": total_files_processed,
            "total_processing_time_seconds": round(total_processing_time, 2),
            "total_tokens_used": total_tokens_used,
            "session_start_time_utc": overall_logs[0]["start_time_utc"] if overall_logs else "N/A",
            "session_end_time_utc": overall_logs[-1]["end_time_utc"] if overall_logs else "N/A"
        },
        "file_details": overall_logs
    }
    with open(summary_log_path, "w", encoding="utf-8") as sum_f:
        json.dump(summary_data, sum_f, indent=4, ensure_ascii=False)
    print(f"Session summary logs saved to: {summary_log_path}")
    print(f"Sumaryczne logi sesji zapisano do: {summary_log_path}")


if __name__ == "__main__":
    # Call the main function to process the image folder.
    # Wywołuje główną funkcję do przetwarzania folderu z obrazami.
    process_image_folder()
    print("\n--- Script image-text.py execution finished. ---")
    print("\n--- Zakończono działanie skryptu image-text.py ---")
--- END FILE: scripts/image-text.py ---

--- START FILE: scripts/analysis-summary.py ---
import os
import pdfplumber
import google.generativeai as genai
import textwrap
import datetime
import json  # Import needed for log files
import yaml

# --- PDF Generation Libraries ---
# --- Biblioteki do generowania PDF ---
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

with open("config.yaml", "r") as cr:
    config_vals = yaml.full_load(cr)
KEY = config_vals['KEY']

# --- Path Configuration ---
# --- Konfiguracja ścieżek ---
PDF_INPUT_FOLDER = "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/FOR_ANALYSIS"
OUTPUT_FOLDER = "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/PROCESSED_OUTPUT"
LOG_FOLDER = "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/LOGS"

# Aktualny czas
now = datetime.datetime.now()

# Format ISO 8601 z milisekundami
full_timestamp = now.strftime("%Y-%m-%dT%H:%M:%S.%f%z")

# Define the path to the Ubuntu Mono font file.
# Make sure 'UbuntuMono-R.ttf' is in the same directory as this script, or provide a full path.
# Zdefiniuj ścieżkę do pliku czcionki Ubuntu Mono.
# Upewnij się, że 'UbuntuMono-R.ttf' znajduje się w tym samym katalogu co ten skrypt, lub podaj pełną ścieżkę.
UBUNTU_MONO_FONT_PATH = os.path.join(os.path.dirname(__file__), "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/UbuntuMono-Regular.ttf")

os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs(LOG_FOLDER, exist_ok=True)

# Register the Ubuntu Mono font with ReportLab.
# Zarejestruj czcionkę Ubuntu Mono w ReportLab.
try:
    pdfmetrics.registerFont(TTFont('UbuntuMono', UBUNTU_MONO_FONT_PATH))
    print(f"Font 'UbuntuMono' registered successfully from {UBUNTU_MONO_FONT_PATH}.")
    print(f"Czcionka 'UbuntuMono' zarejestrowana pomyślnie z {UBUNTU_MONO_FONT_PATH}.")
except Exception as e:
    print(
        f"ERROR: Could not register Ubuntu Mono font from {UBUNTU_MONO_FONT_PATH}. Please ensure the file exists and is accessible. Error: {e}")
    print(
        f"BŁĄD: Nie można zarejestrować czcionki Ubuntu Mono z {UBUNTU_MONO_FONT_PATH}. Upewnij się, że plik istnieje i jest dostępny. Błąd: {e}")
    # Fallback to a default font if Ubuntu Mono cannot be registered.
    # W razie problemów z rejestracją, użyj domyślnej czcionki.
    DEFAULT_FONT = "Helvetica"
else:
    DEFAULT_FONT = "UbuntuMono"

FONT_SIZE = 12  # Font size for the PDF output / Rozmiar czcionki dla wyjścia PDF

# --- GEMINI API KEY CONFIGURATION ---
# --- KONFIGURACJA KLUCZA API GEMINI ---
# IMPORTANT: Replace "*****" with your real API key in config.yaml!
# WAŻNE: Zastąp "*****" swoim prawdziwym kluczem API w pliku config.yaml!
GOOGLE_API_KEY = KEY
genai.configure(api_key=GOOGLE_API_KEY)
print("Gemini API configured successfully.")
print("Gemini API skonfigurowane pomyślnie.")

MODEL_NAME = "gemini-1.5-flash"

generation_config = {
    "temperature": 0.2,
    "top_p": 0.9,
    "top_k": 30,
    "max_output_tokens": 4096,
}

safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

model = genai.GenerativeModel(
    model_name=MODEL_NAME,
    generation_config=generation_config,
    safety_settings=safety_settings
)

CHUNK_SIZE = 100_000  # Rozmiar chunka dla pojedynczych dokumentów
OVERALL_SUMMARY_CHUNK_SIZE = 50_000  # Rozmiar chunka dla globalnego podsumowania - można dostosować


# --- Funkcja do ekstrakcji CAŁEGO tekstu ---
def extract_text_from_pdf_full(pdf_path):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        print(f"BŁĄD: Nie można wyodrębnić tekstu z {pdf_path}: {e}")
        return None
    return text.strip()


# --- Funkcja do ekstrakcji tekstu z WYBRANYCH STRON ---
def extract_selected_pages_from_pdf(pdf_path, start_page, end_page):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            num_pages = len(pdf.pages)

            actual_start_index = max(0, start_page - 1)
            actual_end_index = min(num_pages, end_page)

            if actual_start_index >= num_pages:
                print(
                    f"OSTRZEŻENIE: Strona początkowa {start_page} wykracza poza liczbę stron PDF ({num_pages}). Zwracam pusty tekst.")
                return ""
            if actual_start_index >= actual_end_index:
                print(
                    f"OSTRZEŻENIE: Zakres stron ({start_page}-{end_page}) jest nieprawidłowy lub pusty. Zwracam pusty tekst.")
                return ""

            print(
                f"Ekstrakcja stron od {actual_start_index + 1} do {actual_end_index} z pliku '{os.path.basename(pdf_path)}'...")

            for i in range(actual_start_index, actual_end_index):
                page = pdf.pages[i]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
                else:
                    print(f"  INFO: Strona {i + 1} jest pusta lub nie zawiera tekstu.")
    except Exception as e:
        print(f"BŁĄD: Nie można wyodrębnić tekstu z {pdf_path} dla stron {start_page}-{end_page}: {e}")
        return None
    return text.strip()


# --- Funkcja do interaktywnego pobierania zakresu stron ---
def get_page_range_input(pdf_file_name, total_pages):
    while True:
        choice = input(f"Dla pliku '{pdf_file_name}' (łącznie stron: {total_pages}):\n"
                       f"1. Przetwórz wszystkie strony\n"
                       f"2. Podaj zakres stron (np. 10-20)\n"
                       f"Wybierz opcję (1/2): ").strip()

        if choice == '1':
            return 1, total_pages
        elif choice == '2':
            page_range_str = input("Podaj zakres stron (np. 10-20): ").strip()
            try:
                start_str, end_str = page_range_str.split('-')
                start_page = int(start_str)
                end_page = int(end_str)
                if 1 <= start_page <= end_page <= total_pages:
                    return start_page, end_page
                else:
                    print(
                        f"BŁĄD: Nieprawidłowy zakres stron. Upewnij się, że {1} <= początek <= koniec <= {total_pages}.")
            except ValueError:
                print("BŁĄD: Nieprawidłowy format. Użyj formatu 'START-KONIEC', np. '10-20'.")
        else:
            print("Nieprawidłowy wybór. Proszę wybrać 1 lub 2.")


def analyze_text_with_gemini(text_to_analyze, prompt_prefix=""):
    if not text_to_analyze.strip():
        print("INFO: Brak tekstu do analizy. Zwracam pusty string.")
        return "", 0, 0

    chunks = textwrap.wrap(text_to_analyze, CHUNK_SIZE, break_long_words=False, replace_whitespace=False)

    if not chunks:
        print("OSTRZEŻENIE: Tekst nie został podzielony na chunki prawidłowo. Zwracam pusty string.")
        return "", 0, 0

    full_analysis = []
    total_input_tokens = 0
    total_output_tokens = 0

    print(f"Tekst zostanie podzielony na {len(chunks)} części do analizy.")

    for i, chunk in enumerate(chunks):
        print(f"Analizuję część {i + 1}/{len(chunks)} ({len(chunk)} znaków)...")

        base_prompt = (
                f"Jesteś wysoce doświadczonym ekspertem prawnym, specjalizującym się w prawie cywilnym, egzekucyjnym i socjalnym w Polsce. "
                f"Przeanalizuj dokument pod kątem Prawa Polskiego i Unii Europejskiej, zidentyfikuj kluczowe fakty prawne, terminy, strony, roszczenia, zobowiązania, dowody oraz oświadczenia dotyczące sytuacji finansowej i zdrowotnej Łukasza Andruszkiewicza. "
                f"Szczególną uwagę zwróć na: odniesienia do sytuacji finansowej, długów, dochodów, zatrudnienia, prób znalezienia pracy; szczegóły stanu zdrowia, wypadków, urazów, braku ubezpieczenia; wzmianki o próbach uzyskania pomocy od instytucji; konieczność podjęcia pracy zdalnej; oświadczenia dotyczące braku majątku i trudności egzystencji; adresatów, daty i sygnatury akt. Zacytuj odpowiednie artykuły i opisz jakie prawa zostały złamane. "
                f"Wynik podaj w języku Polskim i Angielskim. Podaj również na końcu treść użytego promptu - analogicznie w języku "
                f"Polskim i Angielskim, a także wersję modelu jaki został użyty - czyli: gemini-1.5-flash,"
                f"z pełnym timestamp: " + full_timestamp
        )
        prompt = f"{prompt_prefix}\n\n{base_prompt}\n\nTekst do analizy:\n\n{chunk}"

        current_chunk_input_tokens = 0
        current_chunk_output_tokens = 0
        chunk_analysis_part = ""

        try:
            current_chunk_input_tokens = model.count_tokens(prompt).total_tokens
            total_input_tokens += current_chunk_input_tokens
            print(f"  Szacowane tokeny wejściowe dla tej części: {current_chunk_input_tokens}")

            response = model.generate_content(prompt)

            if response.parts:
                chunk_analysis_part = "".join([part.text for part in response.parts]).strip()
                full_analysis.append(chunk_analysis_part)

                try:
                    if hasattr(response, '_result') and 'usageMetadata' in response._result:
                        usage_metadata = response._result['usageMetadata']
                        current_chunk_output_tokens = usage_metadata.get('candidatesTokenCount', 0)
                        print(
                            f"  Wygenerowane tokeny wyjściowe dla tej części (z usageMetadata): {current_chunk_output_tokens}")
                    else:
                        print(
                            "  Brak usageMetadata w odpowiedzi, mimo obecności treści. Oszacowanie tokenów wyjściowych na podstawie tekstu.")
                        current_chunk_output_tokens = model.count_tokens(chunk_analysis_part).total_tokens
                        print(f"  Oszacowane tokeny wyjściowe dla tej części (z tekstu): {current_chunk_output_tokens}")
                except Exception as usage_e:
                    print(f"BŁĄD podczas pobierania usageMetadata dla części {i + 1}: {usage_e}")
                    print("  Oszacowanie tokenów wyjściowych na podstawie wygenerowanego tekstu.")
                    current_chunk_output_tokens = model.count_tokens(chunk_analysis_part).total_tokens
                    print(f"  Oszacowane tokeny wyjściowe dla tej części (z tekstu): {current_chunk_output_tokens}")
            else:
                print(
                    f"OSTRZEŻENIE: Gemini nie zwróciło żadnego tekstu (response.parts jest puste) dla części {i + 1}.")
                if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                    print(f"  Feedback od Gemini (Prompt Feedback): {response.prompt_feedback}")
                    full_analysis.append(f"[PROBLEM: FEEDBACK OD GEMINI - {response.prompt_feedback}]\n")
                if hasattr(response, 'candidates') and response.candidates:
                    print("  Dostępne kandydujące odpowiedzi (może zawierać powody blokady):")
                    for candidate in response.candidates:
                        print(f"    Finish Reason: {candidate.finish_reason}")
                        if hasattr(candidate, 'safety_ratings'):
                            print(f"    Safety Ratings: {candidate.safety_ratings}")
                            full_analysis.append(f"[PROBLEM: BEZPIECZEŃSTWO - {candidate.safety_ratings}]\n")
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            print(f"    Content parts (puste?): {candidate.content.parts}")
                else:
                    print("  Brak 'candidates' w odpowiedzi (coś poszło bardzo źle).")
                full_analysis.append(f"[BRAK ANALIZY DLA TEJ CZĘŚCI: PROBLEM Z API LUB TREŚCIĄ]\n")

            total_output_tokens += current_chunk_output_tokens

        except genai.types.BlockedPromptException as e:
            print(f"BŁĄD: Żądanie zablokowane przez Gemini (safety settings) dla części {i + 1}: {e}")
            if hasattr(e, 'response') and e.response:
                print(f"  Szczegóły błędu z API Gemini: {e.response.text}")
                full_analysis.append(f"[ANALIZA ZABLOKOWANA PRZEZ API: {e.response.text}]\n")
            else:
                full_analysis.append(f"[ANALIZA ZABLOKOWANA ZE WZGLĘDÓW BEZPIECZEŃSTWA - BLOCKED PROMPT EXCEPTION]\n")
        except Exception as e:
            print(f"KRYTYCZNY BŁĄD: Podczas komunikacji z Google Gemini dla części {i + 1}: {e}")
            print(f"  Typ błędu: {type(e).__name__}")
            if hasattr(e, 'response') and e.response:
                print(f"  Szczegóły błędu z API Gemini: {e.response.text}")
            full_analysis.append(f"[BŁĄD ANALIZY DLA TEJ CZĘŚCI: {e}]\n")

    final_analysis = "\n\n---\n\n".join(full_analysis)
    return final_analysis, total_input_tokens, total_output_tokens


# --- Nowa funkcja do globalnego podsumowania ---
def summarize_overall_legal_findings(all_summaries_text):
    print("\n\n--- Generowanie globalnego podsumowania prawnego ---")
    if not all_summaries_text.strip():
        print("Brak danych do globalnego podsumowania. Zwracam pusty tekst.")
        return "", 0, 0

    overall_chunks = textwrap.wrap(all_summaries_text, OVERALL_SUMMARY_CHUNK_SIZE, break_long_words=False,
                                   replace_whitespace=False)

    overall_summary_parts = []
    overall_input_tokens = 0
    overall_output_tokens = 0

    base_overall_prompt = (
        f"Jesteś wysoce doświadczonym ekspertem prawnym, specjalizującym się w prawie cywilnym, egzekucyjnym i socjalnym w Polsce. "
        f"Twoim zadaniem jest przygotowanie kompleksowych i rzeczowych wyjaśnień dla Kancelarii Komorniczych, "
        f"bazując na całości dostarczonego dokumentu (połączonego z wielu źródeł). "
        f"Celem jest przedstawienie aktualnej, bardzo trudnej sytuacji finansowej, zdrowotnej i życiowej dłużnika Łukasza Andruszkiewicza, "
        f"zgodnie z wezwaniem od Komornika Joanny Majdak (odwołując się do treści dokumentu). "
        f"W swoich wyjaśnieniach, uwzględnij i szczegółowo opisz następujące punkty, odwołując się do treści dokumentu i przekazanych informacji:"
        f"\n\n1.  **Potwierdzenie aktualnej trudnej sytuacji:** Jasno zaznacz, że sytuacja dłużnika nie uległa poprawie od poprzednich wyjaśnień i jest bardzo trudna (odwołaj się do dokumentów np. 'SPRZECIW_Nc-e_1932318_24_2025-04-27.pdf' oraz 'Gmail - Wyjaśnienia 2024-08-12.PDF', wskazując na pogorszenie i brak możliwości spłaty). "
        f"\n\n2.  **Szczegółowy opis stanu zdrowia i jego wpływu na sytuację:** "
        f"    Wspomnij o wypadku z 1 maja, nieleczonych urazach (oczodół, policzek, zęby, staw skroniowo-żuchwowy, kolano, ścięgno Achillesa), braku ubezpieczenia zdrowotnego i niemożności odbycia badań kontrolnych (odwołaj się do 'Gmail - KM 1623_22.pdf' oraz 'Cover Letter.pdf'). "
        f"    Podkreśl zagrożenie neuralgią nerwu trójdzielnego jako konsekwencję urazów ('SPRZECIW_Nc-e_1932318_24_2025-04-27.pdf'). "
        f"    Wspomnij o braku wsparcia instytucjonalnego w kwestii zdrowia i ubezpieczenia (np. odmowa PUP). "
        f"\n\n3.  **Opis sytuacji finansowej i majątkowej:** "
        f"    Zadeklaruj brak możliwości spłaty zadłużenia. "
        f"    Jasno określ, że jedyną rzeczą, jaką udało się nabyć, są przedmioty z faktury 'F_2025_19384_1.pdf' (adapter dysku NVME M.2, Raspberry Pi 256GB SSD, koszt dostawy), podając ich wartość. "
        f"    Wyjaśnij pochodzenie środków na ten zakup: ostatnie odłożone pieniądze od zeszłego roku, w tym 100 PLN od Brata na święta i 100 PLN od rodziców za rozliczenie zeznań podatkowych w bieżącym roku. "
        f"    Podkreśl, że był to **konieczny wydatek** w celu dokończenia portfolio związanego z ekosystemem TAK, co jest kluczowe dla prób zarobienia pieniędzy. "
        f"    Wspomnij o aktywnych, lecz dotychczas bezskutecznych próbach znalezienia zatrudnienia/współpracy, co prowadzi do braku dochodów. "
        f"    Potwierdź, że dłużnik nie posiada innych znaczących środków ani majątku poza wymienionymi. "
        f"    Odwołaj się do wszelkich wcześniejszych oświadczeń o trudnej sytuacji finansowej, wyzysku, braku wsparcia od Państwa Polskiego i UE, oraz żądaniach odszkodowań (np. w 'SPRZECIW_2025-03-03.pdf', 'ODWOŁANIE-SeriaP_Nr0360-2025-01-13_GOV-PL_2025-01-30'). "
        f"\n\n4.  **Konsekwencje i oczekiwania dłużnika:** "
        f"    Wspomnij o konieczności prowadzenia korespondencji z zagranicy i braku odpowiedzi. "
        f"    Zaznacz, że dłużnik żąda prawnika, którego wynagrodzenie pokryje Fundusz Sprawiedliwości, oraz renty czasowej z ubezpieczeniem zdrowotnym, aby mógł zadbać o swoje zdrowie i przeprowadzić upadłość. ('SPRZECIW_2025-03-03.pdf') "
        f"    Podkreśl, że dłużnik nie jest w stanie obecnie stawiać się przed instytucjami w regionie (Dolny Śląsk) ze względu na doświadczenia (odwołaj się do 'Pismo Właściwe.pdf' oraz 'SPRZECIW_2025-03-03.pdf')."
        f"\n\nZadbaj o to, aby wyjaśnienia były kompleksowe, spójne, rzeczowe i empatyczne, jednocześnie ściśle trzymając się faktów zawartych w dokumentacji. Tekst wygenerowany przez model będzie stanowił trzon pisma do kancelarii komorniczej."
    )

    for i, chunk in enumerate(overall_chunks):
        print(f"Analizuję część {i + 1}/{len(overall_chunks)} globalnego podsumowania ({len(chunk)} znaków)...")
        prompt = f"{base_overall_prompt}\n\nAnalizy do podsumowania:\n\n{chunk}"

        chunk_input_tokens = 0
        chunk_output_tokens = 0
        current_summary_part = ""

        try:
            chunk_input_tokens = model.count_tokens(prompt).total_tokens
            overall_input_tokens += chunk_input_tokens
            print(f"  Szacowane tokeny wejściowe dla tej części globalnego podsumowania: {chunk_input_tokens}")

            response = model.generate_content(prompt)

            if response.parts:
                current_summary_part = "".join([part.text for part in response.parts]).strip()
                overall_summary_parts.append(current_summary_part)

                try:
                    if hasattr(response, '_result') and 'usageMetadata' in response._result:
                        usage_metadata = response._result['usageMetadata']
                        chunk_output_tokens = usage_metadata.get('candidatesTokenCount', 0)
                        print(
                            f"  Wygenerowane tokeny wyjściowe dla tej części (z usageMetadata): {chunk_output_tokens}")
                    else:
                        print(
                            "  Brak usageMetadata w odpowiedzi, mimo obecności treści. Oszacowanie tokenów wyjściowych na podstawie tekstu.")
                        chunk_output_tokens = model.count_tokens(current_summary_part).total_tokens
                        print(f"  Oszacowane tokeny wyjściowe dla tej części (z tekstu): {chunk_output_tokens}")
                except Exception as usage_e:
                    print(
                        f"BŁĄD podczas pobierania usageMetadata dla części globalnego podsumowania {i + 1}: {usage_e}")
                    print("  Oszacowanie tokenów wyjściowych na podstawie wygenerowanego tekstu.")
                    chunk_output_tokens = model.count_tokens(current_summary_part).total_tokens
                    print(f"  Oszacowane tokeny wyjściowe dla tej części (z tekstu): {chunk_output_tokens}")
            else:
                print(f"OSTRZEŻENIE: Gemini nie zwróciło żadnego tekstu dla globalnego podsumowania (część {i + 1}).")
                if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                    print(f"  Feedback od Gemini: {response.prompt_feedback}")
                overall_summary_parts.append(f"[BRAK PODSUMOWANIA DLA TEJ CZĘŚCI: PROBLEM Z API LUB TREŚCIĄ]\n")

            overall_output_tokens += chunk_output_tokens

        except genai.types.BlockedPromptException as e:
            print(f"BŁĄD: Globalne podsumowanie zablokowane przez Gemini (safety settings) dla części {i + 1}: {e}")
            overall_summary_parts.append(f"[GLOBALNE PODSUMOWANIE ZABLOKOWANE PRZEZ API]\n")
        except Exception as e:
            print(
                f"KRYTYCZNY BŁĄD: Podczas komunikacji z Google Gemini dla globalnego podsumowania (część {i + 1}): {e}")
            overall_summary_parts.append(f"[GLOBALNE PODSUMOWANIE: BŁĄD ANALIZY DLA TEJ CZĘŚCI: {e}]\n")

    final_overall_summary = "\n\n".join(overall_summary_parts)
    return final_overall_summary, overall_input_tokens, overall_output_tokens


def write_usage_summary(total_files, total_input_tokens, total_output_tokens, total_duration,
                        overall_summary_input_tokens=0, overall_summary_output_tokens=0):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file_path = os.path.join(LOG_FOLDER, f"gemini_usage_summary_{timestamp}.txt")

    summary_content = (
        f"--- Podsumowanie Uruchomienia BLOX-TAK-GEMINI ---\n"
        f"Data i czas uruchomienia: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"Przetworzone plików PDF: {total_files}\n"
        f"Użyty model Gemini: {MODEL_NAME}\n"
        f"Całkowita liczba tokenów wejściowych (prompt - per dokument): {total_input_tokens}\n"
        f"Całkowita liczba tokenów wyjściowych (generacja - per dokument): {total_output_tokens}\n"
        f"Całkowita liczba tokenów wejściowych (prompt - globalne podsumowanie): {overall_summary_input_tokens}\n"
        f"Całkowita liczba tokenów wyjściowych (generacja - globalne podsumowanie): {overall_summary_output_tokens}\n"
        f"Łączny czas przetwarzania: {total_duration:.2f} sekund\n"
        f"--------------------------------------------------\n"
        f"UWAGA: Jeśli tokeny wyjściowe wynoszą 0 lub są podejrzanie niskie mimo wygenerowanej treści, "
        f"może to oznaczać problem z API lub blokadę treści przez filtry bezpieczeństwa Gemini, "
        f"lub błąd w pobieraniu usageMetadata. Sprawdź logi konsoli powyżej dla 'Feedback od Gemini' lub 'Safety Ratings'.\n"
    )

    try:
        with open(log_file_path, "w", encoding="utf-8") as f:
            f.write(summary_content)
        print(f"\n--- Podsumowanie zużycia zapisano do: {log_file_path} ---")
    except Exception as e:
        print(f"BŁĄD: Nie można zapisać pliku podsumowania zużycia: {e}")


# --- New function to save text to PDF ---
# --- Nowa funkcja do zapisywania tekstu do PDF ---
def save_text_to_pdf(text_content, output_pdf_path, font_name, font_size):
    print(f"Saving text to PDF: {output_pdf_path} with font '{font_name}' {font_size}pt...")
    print(f"Zapisywanie tekstu do PDF: {output_pdf_path} czcionką '{font_name}' {font_size}pkt...")
    try:
        c = canvas.Canvas(output_pdf_path, pagesize=A4)
        c.setFont(font_name, font_size)
        width, height = A4

        # Margins / Marginesy
        left_margin = 50
        top_margin = height - 50
        line_height = font_size * 1.2  # Adjust for spacing / Dostosuj do odstępów

        y_position = top_margin

        lines = []
        for paragraph in text_content.split('\n'):
            wrapped_lines = []
            if paragraph.strip():
                char_width = pdfmetrics.stringWidth('M', font_name, font_size)
                max_chars_per_line = int((width - 2 * left_margin) / char_width) if char_width > 0 else 100

                current_line = ""
                words = paragraph.split(' ')
                for word in words:
                    if pdfmetrics.stringWidth(current_line + word + ' ', font_name, font_size) < (
                            width - 2 * left_margin):
                        current_line += word + ' '
                    else:
                        wrapped_lines.append(current_line.strip())
                        current_line = word + ' '
                if current_line.strip():
                    wrapped_lines.append(current_line.strip())
            else:
                wrapped_lines.append("")
            lines.extend(wrapped_lines)

        for line in lines:
            if y_position < 50:
                c.showPage()
                c.setFont(font_name, font_size)
                y_position = top_margin

            c.drawString(left_margin, y_position, line)
            y_position -= line_height

        c.save()
        print(f"Successfully saved PDF to: {output_pdf_path}")
        print(f"Pomyślnie zapisano PDF do: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR: Could not save text to PDF '{output_pdf_path}': {e}")
        print(f"BŁĄD: Nie można zapisać tekstu do PDF '{output_pdf_path}': {e}")


def process_all_pdfs_with_gemini():
    print(f"Rozpoczynam analizę plików PDF z folderu: {PDF_INPUT_FOLDER}")

    pdf_files = [f for f in os.listdir(PDF_INPUT_FOLDER) if f.lower().endswith(".pdf")]

    if not pdf_files:
        print("INFO: Brak plików PDF w folderze do analizy.")
        return

    overall_total_input_tokens = 0
    overall_total_output_tokens = 0
    processed_files_count = 0

    legal_summaries = []
    all_individual_analyses_text = []

    start_time = datetime.datetime.now()

    for pdf_file in pdf_files:
        pdf_path = os.path.join(PDF_INPUT_FOLDER, pdf_file)
        base_name = os.path.splitext(pdf_file)[0]
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_txt_path = os.path.join(OUTPUT_FOLDER, f"{base_name}_legal_analysis_{timestamp}.txt")
        output_pdf_path = os.path.join(OUTPUT_FOLDER, f"{base_name}_legal_analysis_{timestamp}.pdf")

        print(f"\n--- Przetwarzanie pliku: {pdf_file} ---")

        num_pages = 0
        try:
            with pdfplumber.open(pdf_path) as pdf:
                num_pages = len(pdf.pages)
        except Exception as e:
            print(
                f"BŁĄD: Nie można otworzyć pliku PDF '{pdf_file}' w celu sprawdzenia liczby stron: {e}. Pomijam plik.")
            error_msg = f"[BŁĄD EKSTRAKCJI TEKSTU Z PDF: {e}]"
            with open(output_txt_path, "w", encoding="utf-8") as f:
                f.write(error_msg)
            save_text_to_pdf(error_msg, output_pdf_path, DEFAULT_FONT, FONT_SIZE)
            continue

        start_p, end_p = get_page_range_input(pdf_file, num_pages)

        extracted_text = extract_selected_pages_from_pdf(pdf_path, start_p, end_p)

        if extracted_text is None:
            print(f"BŁĄZ: Pomijam plik '{pdf_file}' z powodu problemów z ekstrakcją tekstu.")
            summary_content = f"--- Analiza dla pliku: {pdf_file} ---\n[BŁĄD EKSTRAKCJI TEKSTU Z PDF]\n"
            error_msg = "[BŁĄD EKSTRAKCJI TEKSTU Z PDF]"
            with open(output_txt_path, "w", encoding="utf-8") as f:
                f.write(error_msg)
            save_text_to_pdf(error_msg, output_pdf_path, DEFAULT_FONT, FONT_SIZE)
            legal_summaries.append(summary_content)
            all_individual_analyses_text.append(summary_content)
            continue

        if not extracted_text:
            print(
                f"INFO: Plik '{pdf_file}' jest pusty lub nie zawiera tekstu po ekstrakcji dla wybranego zakresu. Pomijam analizę.")
            summary_content = f"--- Analiza dla pliku: {pdf_file} ---\n[PLIK PUSTY LUB BEZ TEKSTU DO ANALIZY]\n"
            info_msg = "[PLIK PUSTY LUB BEZ TEKSTU DO ANALIZY]"
            with open(output_txt_path, "w", encoding="utf-8") as f:
                f.write(info_msg)
            save_text_to_pdf(info_msg, output_pdf_path, DEFAULT_FONT, FONT_SIZE)
            legal_summaries.append(summary_content)
            all_individual_analyses_text.append(summary_content)
            continue

        legal_analysis_result, file_input_tokens, file_output_tokens = analyze_text_with_gemini(extracted_text)

        overall_total_input_tokens += file_input_tokens
        overall_total_output_tokens += file_output_tokens
        processed_files_count += 1

        if legal_analysis_result is not None and legal_analysis_result.strip():
            try:
                with open(output_txt_path, "w", encoding="utf-8") as f:
                    f.write(legal_analysis_result)
                print(f"SUKCES: Wynik analizy prawnej zapisano do TXT: {output_txt_path}")

                save_text_to_pdf(legal_analysis_result, output_pdf_path, DEFAULT_FONT, FONT_SIZE)

                summary_content = f"--- Analiza dla pliku: {pdf_file} ---\n" + legal_analysis_result + "\n"
            except Exception as e:
                print(f"BŁĄD: Nie można zapisać wyniku analizy dla {pdf_file}: {e}")
                summary_content = f"--- Analiza dla pliku: {pdf_file} ---\n[BŁĄD ZAPISU WYNIKU ANALIZY: {e}]\n"
                save_text_to_pdf(summary_content, output_pdf_path, DEFAULT_FONT, FONT_SIZE)
        else:
            print(
                f"OSTRZEŻENIE: Nie uzyskano sensownego wyniku analizy dla '{pdf_file}'. Nie zapisano pliku wyjściowego TXT.")
            summary_content = f"--- Analiza dla pliku: {pdf_file} ---\n[NIE UZYSKANO WYNIKU ANALIZY Z GEMINI]\n"
            info_msg = "[NIE UZYSKANO WYNIKU ANALIZY Z GEMINI]"
            with open(output_txt_path, "w", encoding="utf-8") as f:
                f.write(info_msg)
            save_text_to_pdf(info_msg, output_pdf_path, DEFAULT_FONT, FONT_SIZE)

        legal_summaries.append(summary_content)
        all_individual_analyses_text.append(
            legal_analysis_result if legal_analysis_result else summary_content)

        print(f"--- Zużycie tokenów dla pliku '{pdf_file}' ---")
        print(f"  Tokeny wejściowe: {file_input_tokens}")
        print(f"  Tokeny wyjściowe: {file_output_tokens}")
        print("-------------------------------------------------")

    end_time = datetime.datetime.now()
    total_processing_duration = (end_time - start_time).total_seconds()

    print("\n--- Zakończono przetwarzanie wszystkich plików PDF. ---")

    print("\n\n--- ZBIORCZE PODSUMOWANIE PRAWNE DLA KAŻDEGO DOKUMENTU ---")
    for summary in legal_summaries:
        print(summary)
    print("----------------------------------------------------------\n")

    combined_analyses_for_overall_summary = "\n\n".join(filter(None, all_individual_analyses_text))
    overall_legal_summary, overall_summary_input_tokens, overall_summary_output_tokens = \
        summarize_overall_legal_findings(combined_analyses_for_overall_summary)

    print("\n\n--- GLOBALNE PODSUMOWANIE PRAWNE (dla wszystkich dokumentów) ---")
    if overall_legal_summary.strip():
        print(overall_legal_summary)
        global_summary_txt_file_path = os.path.join(OUTPUT_FOLDER,
                                                    f"GLOBAL_LEGAL_SUMMARY_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        try:
            with open(global_summary_txt_file_path, "w", encoding="utf-8") as f:
                f.write(overall_legal_summary)
            print(f"\nGlobalne podsumowanie zapisano do TXT: {global_summary_txt_file_path}")
        except Exception as e:
            print(f"BŁĄD: Nie można zapisać globalnego podsumowania do TXT: {e}")

        global_summary_pdf_file_path = os.path.join(OUTPUT_FOLDER,
                                                    f"GLOBAL_LEGAL_SUMMARY_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf")
        save_text_to_pdf(overall_legal_summary, global_summary_pdf_file_path, DEFAULT_FONT, FONT_SIZE)

    else:
        print("[BRAK GLOBALNEGO PODSUMOWANIA - MOŻLIWY PROBLEM Z API LUB BRAK TREŚCI]")
        save_text_to_pdf("[BRAK GLOBALNEGO PODSUMOWANIA - MOŻLIWY PROBLEM Z API LUB BRAK TREŚCI]",
                         os.path.join(OUTPUT_FOLDER,
                                      f"GLOBAL_LEGAL_SUMMARY_ERROR_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"),
                         DEFAULT_FONT, FONT_SIZE)

    print("------------------------------------------------------------------\n")

    write_usage_summary(processed_files_count, overall_total_input_tokens, overall_total_output_tokens,
                        total_processing_duration, overall_summary_input_tokens, overall_summary_output_tokens)


if __name__ == "__main__":
    process_all_pdfs_with_gemini()
--- END FILE: scripts/analysis-summary.py ---

--- START FILE: scripts/pdf_merger_with_titles.py ---
import os
import pdfplumber
import datetime
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# --- Path Configuration / Konfiguracja ścieżek ---
# Source folder for PDF files
# Folder źródłowy dla plików PDF
PDF_SOURCE_FOLDER = "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/TEMP"
# Destination folder for the output PDF file intended for analysis
# Folder docelowy dla wynikowego pliku PDF przeznaczonego do analizy
OUTPUT_FOR_ANALYSIS_FOLDER = "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/FOR_ANALYSIS"

# Define the path to the Ubuntu Mono font file.
# Ensure 'UbuntuMono-Regular.ttf' is in the same location or provide a full path.
# Zdefiniuj ścieżkę do pliku czcionki Ubuntu Mono.
# Upewnij się, że 'UbuntuMono-Regular.ttf' znajduje się w tej samej lokalizacji lub podaj pełną ścieżkę.
UBUNTU_MONO_FONT_PATH = os.path.join(os.path.dirname(__file__),
                                     "/home/luke_blue_lox/PycharmProjects/BLOX-TAK-GEMINI/UbuntuMono-Regular.ttf")

# Create folders if they do not exist
# Utwórz foldery, jeśli nie istnieją
os.makedirs(PDF_SOURCE_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOR_ANALYSIS_FOLDER, exist_ok=True)

# Register the Ubuntu Mono font with ReportLab.
# Zarejestruj czcionkę Ubuntu Mono w ReportLab.
try:
    pdfmetrics.registerFont(TTFont('UbuntuMono', UBUNTU_MONO_FONT_PATH))
    print(f"Font 'UbuntuMono' registered successfully from {UBUNTU_MONO_FONT_PATH}.")
    print(f"Czcionka 'UbuntuMono' zarejestrowana pomyślnie z {UBUNTU_MONO_FONT_PATH}.")
    DEFAULT_FONT = "UbuntuMono"
except Exception as e:
    print(
        f"ERROR: Could not register Ubuntu Mono font from {UBUNTU_MONO_FONT_PATH}. Please ensure the file exists and is accessible. Error: {e}")
    print(
        f"BŁĄD: Nie można zarejestrować czcionki Ubuntu Mono z {UBUNTU_MONO_FONT_PATH}. Upewnij się, że plik istnieje i jest dostępny. Błąd: {e}")
    DEFAULT_FONT = "Helvetica"  # Fallback to a default font / Fallback do domyślnej czcionki

FONT_SIZE = 12  # Font size for PDF output / Rozmiar czcionki dla wyjścia PDF


# --- Function to extract text from SELECTED PAGES / Funkcja do ekstrakcji tekstu z WYBRANYCH STRON ---
def extract_selected_pages_from_pdf(pdf_path, start_page, end_page):
    """
    Extracts text from a specified page range of a PDF file.
    Ekstrahuje tekst z określonego zakresu stron pliku PDF.

    Args:
        pdf_path (str): Path to the PDF file. / Ścieżka do pliku PDF.
        start_page (int): Starting page number (1-based). / Numer strony początkowej (od 1).
        end_page (int): Ending page number (inclusive). / Numer strony końcowej (włącznie).

    Returns:
        str: Extracted text. Returns an empty string if no text, or None on error.
             Wyekstrahowany tekst. Zwraca pusty string, jeśli nie ma tekstu lub None w przypadku błędu.
    """
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            num_pages = len(pdf.pages)

            # Adjust page indices to Python's 0-based range and ensure they are within bounds
            # Dostosuj indeksy stron do zakresu Pythona (0-based) i upewnij się, że są w granicach
            actual_start_index = max(0, start_page - 1)
            actual_end_index = min(num_pages, end_page)

            if actual_start_index >= num_pages:
                print(
                    f"WARNING: Start page {start_page} exceeds the number of PDF pages ({num_pages}). Returning empty text.")
                print(
                    f"OSTRZEŻENIE: Strona początkowa {start_page} wykracza poza liczbę stron PDF ({num_pages}). Zwracam pusty tekst.")
                return ""
            if actual_start_index >= actual_end_index:
                print(f"WARNING: Page range ({start_page}-{end_page}) is invalid or empty. Returning empty text.")
                print(
                    f"OSTRZEŻENIE: Zakres stron ({start_page}-{end_page}) jest nieprawidłowy lub pusty. Zwracam pusty tekst.")
                return ""

            print(
                f"Extracting pages from {actual_start_index + 1} to {actual_end_index} from file '{os.path.basename(pdf_path)}'...")
            print(
                f"Ekstrakcja stron od {actual_start_index + 1} do {actual_end_index} z pliku '{os.path.basename(pdf_path)}'...")

            for i in range(actual_start_index, actual_end_index):
                page = pdf.pages[i]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
                else:
                    print(f"  INFO: Page {i + 1} is empty or contains no text.")
                    print(f"  INFO: Strona {i + 1} jest pusta lub nie zawiera tekstu.")
    except Exception as e:
        print(f"ERROR: Could not extract text from {pdf_path} for pages {start_page}-{end_page}: {e}")
        print(f"BŁĄD: Nie można wyodrębnić tekstu z {pdf_path} dla stron {start_page}-{end_page}: {e}")
        return None
    return text.strip()


# --- Function for interactive page range input / Funkcja do interaktywnego pobierania zakresu stron ---
def get_page_range_input(pdf_file_name, total_pages):
    """
    Interactively prompts the user for the page range to process for a given PDF file.
    Interaktywnie prosi użytkownika o zakres stron do przetworzenia dla danego pliku PDF.

    Args:
        pdf_file_name (str): Name of the PDF file. / Nazwa pliku PDF.
        total_pages (int): Total number of pages in the PDF file. / Całkowita liczba stron w pliku PDF.

    Returns:
        tuple: A tuple (start_page, end_page) with the selected range.
               Krotka (start_page, end_page) z wybranym zakresem.
    """
    while True:
        choice = input(f"For file '{pdf_file_name}' (total pages: {total_pages}):\n"
                       f"Dla pliku '{pdf_file_name}' (łącznie stron: {total_pages}):\n"
                       f"1. Process all pages / Przetwórz wszystkie strony\n"
                       f"2. Specify page range (e.g., 10-20) / Podaj zakres stron (np. 10-20)\n"
                       f"Choose an option (1/2): / Wybierz opcję (1/2): ").strip()

        if choice == '1':
            return 1, total_pages
        elif choice == '2':
            page_range_str = input("Enter page range (e.g., 10-20): / Podaj zakres stron (np. 10-20): ").strip()
            try:
                start_str, end_str = page_range_str.split('-')
                start_page = int(start_str)
                end_page = int(end_str)
                if 1 <= start_page <= end_page <= total_pages:
                    return start_page, end_page
                else:
                    print(f"ERROR: Invalid page range. Ensure that {1} <= start <= end <= {total_pages}.")
                    print(
                        f"BŁĄD: Nieprawidłowy zakres stron. Upewnij się, że {1} <= początek <= koniec <= {total_pages}.")
            except ValueError:
                print("ERROR: Invalid format. Use 'START-END' format, e.g., '10-20'.")
                print("BŁĄD: Nieprawidłowy format. Użyj formatu 'START-KONIEC', np. '10-20'.")
        else:
            print("Invalid choice. Please select 1 or 2.")
            print("Nieprawidłowy wybór. Proszę wybrać 1 lub 2.")


# Function to save text to PDF with titles / Funkcja do zapisywania tekstu do PDF z tytułami
def save_text_to_pdf_with_titles(text_content, output_pdf_path, font_name, font_size):
    """
    Saves the given text content to a PDF file, handling text wrapping and page breaks.
    Zapisuje podany tekst do pliku PDF, z uwzględnieniem zawijania tekstu i podziału na strony.

    Args:
        text_content (str): Text content to save. / Tekst do zapisania.
        output_pdf_path (str): Path where the PDF file should be saved. / Ścieżka, gdzie ma zostać zapisany plik PDF.
        font_name (str): Name of the registered font. / Nazwa zarejestrowanej czcionki.
        font_size (int): Font size. / Rozmiar czcionki.
    """
    print(f"Saving combined text to PDF: {output_pdf_path} with font '{font_name}' {font_size}pt...")
    print(f"Zapisywanie połączonego tekstu do PDF: {output_pdf_path} czcionką '{font_name}' {font_size}pkt...")
    try:
        c = canvas.Canvas(output_pdf_path, pagesize=A4)
        c.setFont(font_name, font_size)
        width, height = A4

        left_margin = 50  # Left margin / Lewy margines
        top_margin = height - 50  # Top margin / Górny margines
        line_height = font_size * 1.4  # Larger spacing for readability / Większy odstęp dla czytelności

        y_position = top_margin

        # Splitting content into lines, considering paragraph breaks
        # Dzielenie zawartości na linie, z uwzględnieniem podziału na akapity
        lines = []
        for paragraph in text_content.split('\n'):
            wrapped_lines = []
            if paragraph.strip():
                # Using pdfmetrics.stringWidth for precise text wrapping
                # Używamy pdfmetrics.stringWidth do precyzyjnego zawijania
                current_line = ""
                words = paragraph.split(' ')
                for word in words:
                    # Check if adding the word fits in the current line
                    # Sprawdź, czy dodanie słowa zmieści się w linii
                    if pdfmetrics.stringWidth(current_line + word + ' ', font_name, font_size) < (
                            width - 2 * left_margin):
                        current_line += word + ' '
                    else:
                        # If not, add the current line and start a new one
                        # Jeśli nie, dodaj bieżącą linię i rozpocznij nową
                        wrapped_lines.append(current_line.strip())
                        current_line = word + ' '
                if current_line.strip():  # Add any remaining words in the current line
                    # Dodaj pozostałe słowa w bieżącej linii
                    wrapped_lines.append(current_line.strip())
            else:
                wrapped_lines.append("")  # Preserve empty lines for paragraph spacing
                # Zachowaj puste linie dla odstępów między akapitami
            lines.extend(wrapped_lines)

        for line in lines:
            if y_position < 50:  # If reaching the bottom margin, create a new page
                # Jeśli dochodzimy do dolnego marginesu, nowa strona
                c.showPage()
                c.setFont(font_name, font_size)
                y_position = top_margin

            c.drawString(left_margin, y_position, line)
            y_position -= line_height

        c.save()
        print(f"Successfully saved combined PDF to: {output_pdf_path}")
        print(f"Pomyślnie zapisano połączony PDF do: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR: Could not save text to PDF '{output_pdf_path}': {e}")
        print(f"BŁĄD: Nie można zapisać tekstu do PDF '{output_pdf_path}': {e}")


def merge_pdfs_with_titles():
    """
    Main function to merge PDF files from the source folder.
    It interactively prompts the user for page selection for each file,
    then combines the extracted text into a single PDF document.
    Główna funkcja do łączenia plików PDF z folderu źródłowego.
    Interaktywnie prosi użytkownika o wybór stron dla każdego pliku,
    a następnie łączy wyekstrahowany tekst w jeden dokument PDF.
    """
    print(f"Starting extraction and merging of PDF files from folder: {PDF_SOURCE_FOLDER}")
    print(f"Rozpoczynam ekstrakcję i łączenie plików PDF z folderu: {PDF_SOURCE_FOLDER}")

    # Get a list of PDF files from the source folder, sorted alphabetically
    # Pobierz listę plików PDF z folderu źródłowego, posortowanych alfabetycznie
    pdf_files = sorted([f for f in os.listdir(PDF_SOURCE_FOLDER) if f.lower().endswith(".pdf")])

    if not pdf_files:
        print("INFO: No PDF files found in the source folder for processing.")
        print("INFO: Brak plików PDF w folderze źródłowym do przetworzenia.")
        return

    combined_text = []  # List to store extracted text from all files
    # Lista do przechowywania wyekstrahowanego tekstu z wszystkich plików

    for pdf_file in pdf_files:
        pdf_path = os.path.join(PDF_SOURCE_FOLDER, pdf_file)
        file_title = os.path.splitext(pdf_file)[0]  # File title without extension
        # Tytuł pliku bez rozszerzenia

        print(f"\n--- Processing file: {pdf_file} ---")
        print(f"\n--- Przetwarzanie pliku: {pdf_file} ---")

        num_pages = 0
        try:
            with pdfplumber.open(pdf_path) as pdf:
                num_pages = len(pdf.pages)
        except Exception as e:
            print(f"ERROR: Could not open PDF file '{pdf_file}' to check page count: {e}. Skipping file.")
            print(
                f"BŁĄD: Nie można otworzyć pliku PDF '{pdf_file}' w celu sprawdzenia liczby stron: {e}. Pomijam plik.")
            combined_text.append(f"\n\n--- FILE SKIPPED (PDF OPEN ERROR): {file_title} ---\n\n")
            combined_text.append(f"\n\n--- PLIK POMINIĘTY (BŁĄD OTWARCIA PDF): {file_title} ---\n\n")
            continue

        start_p, end_p = get_page_range_input(pdf_file, num_pages)  # Get page range from user
        # Pobierz zakres stron od użytkownika
        extracted_text = extract_selected_pages_from_pdf(pdf_path, start_p, end_p)  # Extract text
        # Wyekstrahuj tekst

        if extracted_text is not None:
            # Add file title as a separator before and after its content
            # Dodaj tytuł pliku jako separator przed i po jego zawartości
            combined_text.append(f"\n\n--- BEGINNING OF FILE: {file_title} ---\n\n")
            combined_text.append(f"\n\n--- POCZĄTEK PLIKU: {file_title} ---\n\n")
            combined_text.append(extracted_text)
            combined_text.append(f"\n\n--- END OF FILE: {file_title} ---\n\n")
            combined_text.append(f"\n\n--- KONIEC PLIKU: {file_title} ---\n\n")
        else:
            print(f"WARNING: Could not extract text from '{pdf_file}'. Skipping this file.")
            print(f"OSTRZEŻENIE: Nie można wyodrębnić tekstu z '{pdf_file}'. Pomijam ten plik.")
            combined_text.append(f"\n\n--- FILE SKIPPED (EXTRACTION ERROR): {file_title} ---\n\n")
            combined_text.append(f"\n\n--- PLIK POMINIĘTY (BŁĄD EKSTRAKCJI): {file_title} ---\n\n")

    if combined_text:
        final_combined_text = "\n".join(combined_text)  # Join all text fragments into a single string
        # Połącz wszystkie fragmenty tekstu w jeden string
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_pdf_path = os.path.join(OUTPUT_FOR_ANALYSIS_FOLDER, f"Combined_Legal_Documents_{timestamp}.pdf")

        # Save the combined text to a PDF file
        # Zapisz połączony tekst do pliku PDF
        save_text_to_pdf_with_titles(final_combined_text, output_pdf_path, DEFAULT_FONT, FONT_SIZE)
        print(f"\n--- Finished merging all PDF files to: {output_pdf_path} ---")
        print(f"\n--- Zakończono łączenie wszystkich plików PDF do: {output_pdf_path} ---")
    else:
        print("\nNo text extracted due to errors or missing files.")
        print("\nNie wyodrębniono żadnego tekstu ze względu na błędy lub brak plików.")


if __name__ == "__main__":
    # Entry point of the program. Calls the PDF merging function.
    # Punkt wejścia programu. Wywołuje funkcję łączenia PDF-ów.
    merge_pdfs_with_titles()

--- END FILE: scripts/pdf_merger_with_titles.py ---

--- START FILE: scripts/gemini_corrector.py ---
import uno
import unohelper
import json
import http.client
import yaml

with open("config.yaml", "r") as cr:
    config_vals = yaml.full_load(cr)
KEY = config_vals['KEY']

# Main macro function to correct the entire document text using Google Gemini
# Główna funkcja makra do poprawiania całego tekstu dokumentu za pomocą Google Gemini
def correct_entire_document_text_google(*args):
    # Get the current document
    # Pobierz bieżący dokument
    desktop = XSCRIPTCONTEXT.getDesktop()
    model = desktop.getCurrentComponent()
    if not model:
        print("ERROR: No document open.")
        print("BŁĄD: Brak otwartego dokumentu.")
        return

    # Get the entire text object of the document
    # Pobierz obiekt całego tekstu dokumentu
    text_object = model.Text
    if not text_object:
        print("ERROR: Could not get the document's text object.")
        print("BŁĄD: Nie można uzyskać obiektu tekstu dokumentu.")
        return

    # Get the full text content from the document
    # Pobierz pełną zawartość tekstową z dokumentu
    full_document_text = text_object.getString()

    if not full_document_text.strip():
        print("INFO: The current document is empty or contains only whitespace. Nothing to correct.")
        print("INFO: Bieżący dokument jest pusty lub zawiera tylko białe znaki. Brak tekstu do poprawy.")
        return

    print(f"Text to correct (first 100 characters): {full_document_text[:100]}...")
    print(f"Tekst do poprawy (pierwsze 100 znaków): {full_document_text[:100]}...")

    # --- GEMINI API KEY CONFIGURATION ---
    # --- KONFIGURACJA KLUCZA API GEMINI ---
    # IMPORTANT: Replace "*****" with your real API key in config.yaml!
    # WAŻNE: Zastąp "*****" swoim prawdziwym kluczem API w pliku config.yaml!
    GOOGLE_API_KEY = KEY
    print("Gemini API configured successfully.")
    print("Gemini API skonfigurowane pomyślnie.")

    API_HOST = "generativelanguage.googleapis.com"
    MODEL_NAME = "gemini-1.5-flash-8b"

    # Prepare the prompt for Gemini
    # Przygotuj prompt dla Gemini
    prompt_content = (
        f"Correct spelling, grammar, and stylistic errors in the following Polish text. "
        f"Ensure the text is grammatically correct and sounds natural in Polish. "
        f"Return only the corrected text, without additional comments. Text to correct:\n\n{full_document_text}"
    )
    prompt_content_pl = (
        f"Popraw błędy ortograficzne, gramatyczne i stylistyczne w poniższym tekście. "
        f"Upewnij się, że tekst jest poprawny językowo i naturalnie brzmiący po polsku. "
        f"Zwróć tylko poprawiony tekst, bez dodatkowych komentarzy. Tekst do poprawy:\n\n{full_document_text}"
    )

    # Structure of the request body for Gemini API
    # Struktura ciała żądania dla API Gemini
    request_body = {
        "contents": [
            {
                "parts": [
                    {"text": prompt_content_pl}  # Using the Polish prompt version
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.7,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": 8192,
        }
    }

    try:
        # Connect to Gemini API
        # Połącz się z API Gemini
        conn = http.client.HTTPSConnection(API_HOST)
        headers = {
            'Content-Type': 'application/json',
            'x-goog-api-key': GOOGLE_API_KEY
        }
        endpoint = f"/v1beta/models/{MODEL_NAME}:generateContent"
        body = json.dumps(request_body)

        print(f"Sending request to {API_HOST}{endpoint}...")
        print(f"Wysyłam zapytanie do {API_HOST}{endpoint}...")

        conn.request("POST", endpoint, body=body, headers=headers)
        response = conn.getresponse()
        response_data = response.read().decode('utf-8')
        conn.close()

        print(f"Gemini API Response Status: {response.status}")
        print(f"Status odpowiedzi API Gemini: {response.status}")
        print(f"Full Gemini API Response (for diagnostics): {response_data}")
        print(f"Pełna odpowiedź API Gemini (do diagnostyki): {response_data}")

        # Check if the response is successful
        # Sprawdź, czy odpowiedź jest pomyślna
        if response.status == 200:
            result = json.loads(response_data)
            corrected_text = ""

            # Extract the corrected text from the response
            # Wyodrębnij poprawiony tekst z odpowiedzi
            if 'candidates' in result and len(result['candidates']) > 0 \
                    and 'content' in result['candidates'][0] \
                    and 'parts' in result['candidates'][0]['content'] \
                    and len(result['candidates'][0]['content']['parts']) > 0 \
                    and 'text' in result['candidates'][0]['content']['parts'][0]:

                corrected_text = result['candidates'][0]['content']['parts'][0]['text'].strip()

                if corrected_text:
                    # Replace the entire document text with the corrected text
                    # Zastąp cały tekst dokumentu poprawionym tekstem
                    text_object.setString(corrected_text)
                    print("SUCCESS: Entire document text corrected successfully by Google Gemini!")
                    print("SUKCES: Cały tekst dokumentu poprawiony pomyślnie przez Google Gemini!")
                else:
                    print("WARNING: Gemini returned an empty corrected text.")
                    print("OSTRZEŻENIE: Gemini zwróciło pusty poprawiony tekst.")
            else:
                print("ERROR: Invalid Gemini API response structure (missing 'candidates' or 'content').")
                print("BŁĄD: Nieprawidłowa struktura odpowiedzi API Gemini (brak 'candidates' lub 'content').")

            # Display token usage
            # Wyświetl zużycie tokenów
            if 'usageMetadata' in result:
                usage = result['usageMetadata']
                usage_msg = (
                    f"Model: {result.get('modelVersion', 'Unknown version')}\n"
                    f"Input Tokens: {usage.get('promptTokenCount', 0)}\n"
                    f"Output Tokens: {usage.get('candidatesTokenCount', 0)}\n"
                    f"Total Tokens: {usage.get('totalTokenCount', 0)}"
                )
                print(f"--- Gemini Resource Usage ---\n{usage_msg}")
                print(f"--- Zużycie zasobów Gemini ---\n{usage_msg}")
            else:
                print("INFO: No token usage information in Gemini response.")
                print("INFO: Brak informacji o zużyciu tokenów w odpowiedzi Gemini.")

        else:
            print(f"ERROR: Google Gemini server error: HTTP {response.status} - {response_data}")
            print(f"BŁĄD: Błąd serwera Google Gemini: HTTP {response.status} - {response_data}")

    except Exception as e:
        print(f"CRITICAL ERROR: During communication with Google Gemini: {e}")
        print(f"KRYTYCZNY BŁĄD: Podczas komunikacji z Google Gemini: {e}")


# Register the macro for LibreOffice
# Rejestracja makra dla LibreOffice
g_exportedScripts = correct_entire_document_text_google,
--- END FILE: scripts/gemini_corrector.py ---

--- START FILE: scripts/universal_content_merger.py ---
# For filesystem operations like creating paths and folders. / Do operacji na systemie plików, jak tworzenie ścieżek i folderów.
import os
# For opening and extracting text from PDF files, and converting pages to images. / Do otwierania i wyciągania tekstu z plików PDF oraz konwertowania stron na obrazy.
import pdfplumber
# For generating unique timestamps for filenames. / Do generowania unikalnych znaczników czasu dla nazw plików.
import datetime
# For loading configuration files in YAML format. / Do wczytywania plików konfiguracyjnych w formacie YAML.
import yaml
# For system interaction, e.g., to exit the script. / Do interakcji z systemem, np. do przerwania działania skryptu.
import sys
# For creating temporary files to handle image conversion for OCR. / Do tworzenia plików tymczasowych do obsługi konwersji obrazów dla OCR.
import tempfile
# For using regular expressions to find dates in filenames. / Do używania wyrażeń regularnych w celu znalezienia dat w nazwach plików.
import re
# For structured logging in JSON format. / Do strukturalnego logowania w formacie JSON.
import json
# For timing operations. / Do mierzenia czasu operacji.
import time
# The official Google library for interacting with the Gemini API. / Oficjalna biblioteka Google do interakcji z API Gemini.
import google.generativeai as genai

# ReportLab imports for advanced text wrapping and PDF creation
# Importy ReportLab do zaawansowanego zawijania tekstu i tworzenia PDF
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib.enums import TA_JUSTIFY, TA_LEFT


# --- MAIN CONFIGURATION LOADING FUNCTION ---
# --- GŁÓWNA FUNKCJA ŁADUJĄCA KONFIGURACJĘ ---
def load_configuration(config_path='config.yaml'):
    """
    Loads configuration from a YAML file.
    Wczytuje konfigurację z pliku YAML.
    """
    try:
        with open(config_path, "r", encoding="utf-8") as cr:
            config = yaml.full_load(cr)

        if 'base_path' not in config:
            raise ValueError("Key 'base_path' is required in the configuration file.")
        if 'merger_script_config' not in config:
            raise ValueError("Section 'merger_script_config' is required in the configuration file.")
        if 'KEY' not in config or not config['KEY'] or config['KEY'] == "TWOJ_KLUCZ_API_GEMINI" or config[
            'KEY'] == "*****":
            raise ValueError("Gemini API Key ('KEY') not found, is empty, or is a placeholder.")

        base_path = config['base_path']
        merger_config = config['merger_script_config']

        conf = {
            "GEMINI_API_KEY": config['KEY'],
            "SOURCE_FOLDER": os.path.join(base_path, merger_config.get('source_folder', 'TEMP')),
            "OUTPUT_FOLDER": os.path.join(base_path, merger_config.get('output_folder', 'FOR_ANALYSIS')),
            "LOG_FOLDER": os.path.join(base_path, merger_config.get('log_folder', 'LOGS')),
            "FONT_PATH": os.path.join(base_path, merger_config.get('font_path', 'UbuntuMono-Regular.ttf')),
            "FONT_NAME": merger_config.get('font_name', 'UbuntuMono'),
            "FONT_SIZE": merger_config.get('font_size', 10),
            "MODEL_NAME": merger_config.get('model_name', 'gemini-1.5-flash'),
            "OCR_PROMPT": merger_config.get('ocr_prompt',
                                            'GEMINI, Make OCR. Do not add any additional information, just the text.'),
            "AUDIO_PROMPT": merger_config.get('audio_prompt',
                                              'Transcribe the audio recording. Return only the final text.'),
            "OCR_RESOLUTION": merger_config.get('ocr_resolution', 150)
        }

        print("Configuration loaded successfully.")
        print("Konfiguracja załadowana pomyślnie.")
        return conf

    except (FileNotFoundError, ValueError, KeyError) as e:
        print(f"FATAL ERROR in configuration: {e}")
        print(f"BŁĄD KRYTYCZNY w konfiguracji: {e}")
        return None


# --- Initialization of Configuration and Services ---
# --- Inicjalizacja Konfiguracji i Usług ---
CONFIG = load_configuration()
MODEL = None

if CONFIG:
    try:
        genai.configure(api_key=CONFIG['GEMINI_API_KEY'])
        MODEL = genai.GenerativeModel(CONFIG['MODEL_NAME'])
        print(f"Gemini API configured successfully with model: {CONFIG['MODEL_NAME']}")
        print(f"Gemini API skonfigurowane pomyślnie z modelem: {CONFIG['MODEL_NAME']}")
    except Exception as e:
        print(f"ERROR: Could not configure Gemini API: {e}")
        CONFIG = None

    if CONFIG:
        os.makedirs(CONFIG['SOURCE_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['OUTPUT_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['LOG_FOLDER'], exist_ok=True)
        try:
            pdfmetrics.registerFont(TTFont(CONFIG['FONT_NAME'], CONFIG['FONT_PATH']))
            print(f"Font '{CONFIG['FONT_NAME']}' registered successfully.")
            print(f"Czcionka '{CONFIG['FONT_NAME']}' zarejestrowana pomyślnie.")
        except Exception as e:
            print(
                f"ERROR: Could not register font from path '{CONFIG['FONT_PATH']}'. Defaulting to Helvetica. Error: {e}")
            CONFIG['FONT_NAME'] = "Helvetica"
else:
    print("Exiting script due to configuration errors.")
    sys.exit(1)

# --- File Type Constants ---
# --- Stałe typów plików ---
SUPPORTED_PDF_EXT = ('.pdf',)
SUPPORTED_TXT_EXT = ('.txt',)
SUPPORTED_IMG_EXT = ('.png', '.jpg', '.jpeg', '.webp', '.bmp')
SUPPORTED_AUDIO_EXT = ('.mp3', '.wav', '.m4a', '.flac', '.ogg')


# --- Text Extraction Functions ---
# --- Funkcje Ekstrakcji Tekstu ---
def extract_text_from_text_pdf(pdf_path, start_page, end_page):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            num_pages = len(pdf.pages)
            actual_start_index = max(0, start_page - 1)
            actual_end_index = min(num_pages, end_page)

            if actual_start_index >= actual_end_index: return ""

            print(f"Extracting text from pages {actual_start_index + 1} to {actual_end_index}...")
            print(f"Ekstrakcja tekstu ze stron od {actual_start_index + 1} do {actual_end_index}...")
            for i in range(actual_start_index, actual_end_index):
                page = pdf.pages[i]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        print(f"ERROR reading text-based PDF {pdf_path}: {e}")
        return f"[BŁĄD ODCZYTU PLIKU PDF: {e}]", None
    return text.strip(), {}


def extract_text_from_scanned_pdf(pdf_path, start_page, end_page):
    all_pages_text = []
    total_token_usage = {'prompt_token_count': 0, 'candidates_token_count': 0, 'total_token_count': 0}
    try:
        with pdfplumber.open(pdf_path) as pdf:
            num_pages = len(pdf.pages)
            actual_start_index = max(0, start_page - 1)
            actual_end_index = min(num_pages, end_page)

            if actual_start_index >= actual_end_index: return "", {}

            print(
                f"PDF appears to be a scan. Performing OCR on pages {actual_start_index + 1} to {actual_end_index}...")
            print(f"PDF wygląda na skan. Wykonuję OCR na stronach od {actual_start_index + 1} do {actual_end_index}...")

            for i in range(actual_start_index, actual_end_index):
                page = pdf.pages[i]
                img = page.to_image(resolution=CONFIG.get("OCR_RESOLUTION", 150))

                with tempfile.NamedTemporaryFile(suffix=".png", delete=True) as temp_image:
                    img.save(temp_image.name, format="PNG")
                    page_text, usage = extract_text_from_image_with_gemini(temp_image.name)
                    all_pages_text.append(page_text)
                    if usage:
                        total_token_usage['prompt_token_count'] += usage.get('prompt_token_count', 0)
                        total_token_usage['candidates_token_count'] += usage.get('candidates_token_count', 0)
                        total_token_usage['total_token_count'] += usage.get('total_token_count', 0)
    except Exception as e:
        print(f"ERROR during scanned PDF processing {pdf_path}: {e}")
        return f"[BŁĄD PRZETWARZANIA ZESKANOWANEGO PDF: {e}]", None

    return "\n\n--- Page Break ---\n\n".join(all_pages_text), total_token_usage


def extract_text_from_txt(txt_path):
    print(f"Reading text file: {os.path.basename(txt_path)}...")
    print(f"Odczytuję plik tekstowy: {os.path.basename(txt_path)}...")
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            return f.read(), {}
    except Exception as e:
        print(f"ERROR reading TXT {txt_path}: {e}")
        return f"[BŁĄD ODCZYTU PLIKU TXT: {e}]", None


def extract_text_from_image_with_gemini(image_path):
    if not MODEL: return "[OCR ERROR: Gemini API is not configured]", None

    print(f"Performing OCR on image: {os.path.basename(image_path)}...")
    print(f"Przeprowadzam OCR na obrazie: {os.path.basename(image_path)}...")
    try:
        image_file = genai.upload_file(path=image_path)
        response = MODEL.generate_content([CONFIG['OCR_PROMPT'], image_file])
        genai.delete_file(image_file.name)
        usage_metadata = getattr(response, 'usage_metadata', None)
        usage_dict = {}
        if usage_metadata:
            usage_dict = {
                'prompt_token_count': usage_metadata.prompt_token_count,
                'candidates_token_count': usage_metadata.candidates_token_count,
                'total_token_count': usage_metadata.total_token_count
            }
        return response.text.strip(), usage_dict
    except Exception as e:
        print(f"ERROR during OCR on {image_path}: {e}")
        return f"[BŁĄD OCR GEMINI: {e}]", None


def extract_text_from_audio_with_gemini(audio_path):
    if not MODEL: return "[TRANSCRIPTION ERROR: Gemini API is not configured]", None

    print(f"Transcribing audio file: {os.path.basename(audio_path)}...")
    print(f"Przeprowadzam transkrypcję pliku audio: {os.path.basename(audio_path)}...")
    audio_file = None
    try:
        audio_file = genai.upload_file(path=audio_path)
        response = MODEL.generate_content([CONFIG['AUDIO_PROMPT'], audio_file])
        usage_metadata = getattr(response, 'usage_metadata', None)
        usage_dict = {}
        if usage_metadata:
            usage_dict = {
                'prompt_token_count': usage_metadata.prompt_token_count,
                'candidates_token_count': usage_metadata.candidates_token_count,
                'total_token_count': usage_metadata.total_token_count
            }
        return response.text.strip(), usage_dict
    except Exception as e:
        print(f"ERROR during audio transcription of {audio_path}: {e}")
        return f"[BŁĄD TRANSKRYPCJI AUDIO: {e}]", None
    finally:
        if audio_file:
            genai.delete_file(audio_file.name)
            print(f"Cleaned up temporary audio file: {audio_file.name}")
            print(f"Posprzątano tymczasowy plik audio: {audio_file.name}")


# --- Helper Functions and Main Logic ---
# --- Funkcje pomocnicze i główna logika ---
def extract_date_from_path(file_path):
    filename = os.path.basename(file_path)
    match = re.search(r'(\d{4}[-_]?\d{2}[-_]?\d{2})', filename)
    if match:
        date_str = match.group(1).replace('-', '').replace('_', '')
        try:
            return datetime.datetime.strptime(date_str, '%Y%m%d')
        except ValueError:
            pass
    try:
        return datetime.datetime.fromtimestamp(os.path.getmtime(file_path))
    except OSError:
        return datetime.datetime.min


def get_page_range_input(pdf_file_name, total_pages):
    while True:
        choice = input(f"For file '{pdf_file_name}' (total pages: {total_pages}):\n"
                       f"  1. Process all pages\n"
                       f"  2. Specify page range (e.g., 10-20)\n"
                       f"Dla pliku '{pdf_file_name}' (łącznie stron: {total_pages}):\n"
                       f"  1. Przetwórz wszystkie strony\n"
                       f"  2. Podaj zakres stron (np. 10-20)\n"
                       f"Choose an option (1/2) / Wybierz opcję (1/2): ").strip()
        if choice == '1':
            return 1, total_pages
        elif choice == '2':
            page_range_str = input("Enter page range / Podaj zakres stron: ").strip()
            try:
                start, end = map(int, page_range_str.split('-'))
                if 1 <= start <= end <= total_pages:
                    return start, end
                else:
                    print("ERROR: Invalid page range.")
            except ValueError:
                print("ERROR: Invalid format. Use 'START-END'.")
        else:
            print("Invalid choice.")


# --- NEW HELPER FUNCTION TO FIX WRAPPING ---
# --- NOWA FUNKCJA POMOCNICZA DO NAPRAWY ZAWIJANIA ---
def reflow_text(text: str) -> str:
    """
    Intelligently joins lines that have been incorrectly broken mid-sentence.
    Inteligentnie łączy linie, które zostały nieprawidłowo złamane w połowie zdania.
    """
    # Step 1: Replace single newlines (likely incorrect breaks) with a space. / Krok 1: Zamień pojedyncze znaki nowej linii (prawdopodobnie nieprawidłowe złamania) na spację.
    reflowed = re.sub(r'(?<!\n)\n(?!\n)', ' ', text)

    # Step 2: Replace two or more newlines (which signify a paragraph break) with a <br/> tag understood by ReportLab. / Krok 2: Zamień dwa (lub więcej) znaki nowej linii (które oznaczają koniec akapitu) na tag <br/> zrozumiały dla ReportLab.
    reflowed = re.sub(r'\n{2,}', '<br/><br/>', reflowed)

    return reflowed


# --- MODIFIED PDF SAVING FUNCTION ---
# --- ZMODYFIKOWANA FUNKCJA ZAPISU DO PDF ---
def save_text_to_pdf(text_content, output_pdf_path):
    """
    Saves the given text content to a PDF file with proper text wrapping.
    Zapisuje podany tekst do pliku PDF z poprawnym zawijaniem tekstu.
    """
    font_name = CONFIG['FONT_NAME']
    font_size = CONFIG.get('FONT_SIZE', 10)
    print(f"Saving PDF with proper wrapping to: {output_pdf_path}...")
    print(f"Zapisuję PDF z poprawnym zawijaniem do: {output_pdf_path}...")

    # Setup document template. / Ustawienie szablonu dokumentu.
    doc = SimpleDocTemplate(output_pdf_path, pagesize=A4,
                            rightMargin=72, leftMargin=72,
                            topMargin=72, bottomMargin=72)

    # Setup paragraph styles. / Ustawienie stylów akapitu.
    styles = getSampleStyleSheet()
    style = ParagraphStyle(
        name='Normal_Justified',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=font_size,
        leading=font_size * 1.5,
        alignment=TA_JUSTIFY,  # Justify text for a cleaner look. / Justowanie tekstu dla czystszego wyglądu.
    )

    # *** KEY CHANGE: Call the `reflow_text` function before creating the Paragraph. ***
    # *** KLUCZOWA ZMIANA: Wywołanie funkcji `reflow_text` przed utworzeniem akapitu. ***
    processed_text = reflow_text(text_content)

    story = [Paragraph(processed_text, style)]

    # Build the PDF. / Zbuduj (wygeneruj) PDF.
    try:
        doc.build(story)
        print(f"Successfully saved PDF: {output_pdf_path}")
        print(f"Pomyślnie zapisano PDF: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR saving PDF: {e}")
        print(f"BŁĄD podczas zapisywania PDF: {e}")


def write_summary_log(log_data):
    """
    Writes a JSON summary log for the entire session.
    Zapisuje podsumowujący log JSON dla całej sesji.
    """
    log_file_path = os.path.join(CONFIG['LOG_FOLDER'], f"merger_log_{log_data['session_start_iso']}.json")
    try:
        with open(log_file_path, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=4, ensure_ascii=False)
        print("\n--- Summary log created successfully. ---")
        print(f"--- Podsumowujący log został pomyślnie utworzony: {log_file_path} ---")
    except Exception as e:
        print(f"ERROR: Could not write summary log file: {e}")
        print(f"BŁĄD: Nie można zapisać pliku z logami: {e}")


def main():
    """
    Main function to merge content from PDF, TXT, image and audio files.
    Główna funkcja do łączenia treści z plików PDF, TXT, obrazów i audio.
    """
    script_start_time = time.time()
    session_start_iso = datetime.datetime.now().isoformat().replace(":", "-")

    print(f"Starting content merge from folder: {CONFIG['SOURCE_FOLDER']}")
    print(f"Rozpoczynam łączenie treści z folderu: {CONFIG['SOURCE_FOLDER']}")

    all_files = []
    supported_extensions = SUPPORTED_PDF_EXT + SUPPORTED_TXT_EXT + SUPPORTED_IMG_EXT + SUPPORTED_AUDIO_EXT
    for dirpath, _, filenames in os.walk(CONFIG['SOURCE_FOLDER']):
        for filename in filenames:
            if filename.lower().endswith(supported_extensions):
                all_files.append(os.path.join(dirpath, filename))

    print(f"Sorting {len(all_files)} files by date (newest first)...")
    print(f"Sortuję {len(all_files)} plików według daty (od najnowszych)...")
    all_files.sort(key=extract_date_from_path, reverse=True)

    if not all_files:
        print("INFO: No supported files found for processing.")
        print("INFO: Nie znaleziono obsługiwanych plików do przetworzenia.")
        return

    combined_text_parts = []
    session_log_details = []

    for file_path in all_files:
        file_start_time = time.time()
        file_name = os.path.basename(file_path)

        file_log = {"file_name": file_name, "full_path": file_path, "status": "Processing", "details": ""}
        print(f"\n--- Processing file: {file_name} ---")
        print(f"\n--- Przetwarzam plik: {file_name} ---")

        combined_text_parts.append(f"\n\n--- BEGINNING OF FILE: {file_name} ---\n\n")
        combined_text_parts.append(f"--- POCZĄTEK PLIKU: {file_name} ---\n\n")

        extracted_text = ""
        token_usage = {}
        error_message = None

        try:
            if file_name.lower().endswith(SUPPORTED_PDF_EXT):
                with pdfplumber.open(file_path) as pdf:
                    num_pages = len(pdf.pages)
                start_p, end_p = get_page_range_input(file_name, num_pages)
                extracted_text, token_usage = extract_text_from_text_pdf(file_path, start_p, end_p)
                if not extracted_text.strip():
                    extracted_text, token_usage = extract_text_from_scanned_pdf(file_path, start_p, end_p)
            elif file_name.lower().endswith(SUPPORTED_TXT_EXT):
                extracted_text, token_usage = extract_text_from_txt(file_path)
            elif file_name.lower().endswith(SUPPORTED_IMG_EXT):
                extracted_text, token_usage = extract_text_from_image_with_gemini(file_path)
            elif file_name.lower().endswith(SUPPORTED_AUDIO_EXT):
                extracted_text, token_usage = extract_text_from_audio_with_gemini(file_path)

            file_log['status'] = "Success"
        except Exception as e:
            error_message = str(e)
            extracted_text = f"[BŁĄD PRZETWARZANIA PLIKU: {error_message}]"
            file_log['status'] = "ERROR"
            file_log['details'] = error_message

        combined_text_parts.append(extracted_text)
        combined_text_parts.append(f"\n\n--- END OF FILE: {file_name} ---\n\n")
        combined_text_parts.append(f"--- KONIEC PLIKU: {file_name} ---\n\n")

        file_log['processing_time_seconds'] = round(time.time() - file_start_time, 2)
        if token_usage:
            file_log['token_usage'] = {
                'prompt': token_usage.get('prompt_token_count', 0),
                'candidates': token_usage.get('candidates_token_count', 0),
                'total': token_usage.get('total_token_count', 0)
            }
        session_log_details.append(file_log)

    script_end_time = time.time()
    if combined_text_parts:
        final_text = "".join(combined_text_parts)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_pdf_path = os.path.join(CONFIG['OUTPUT_FOLDER'], f"Combined_Content_{timestamp}.pdf")

        # Calling the modified save function. / Wywołanie zmodyfikowanej funkcji zapisu.
        save_text_to_pdf(final_text, output_pdf_path)

        print("\n--- Finished merging all content. ---")
        print("\n--- Zakończono łączenie wszystkich treści. ---")
    else:
        print("\nNo text was extracted from any file.")
        print("\nNie wyekstrahowano tekstu z żadnego pliku.")

    overall_log = {
        "session_start_iso": session_start_iso,
        "total_duration_seconds": round(script_end_time - script_start_time, 2),
        "total_files_processed": len(session_log_details),
        "processed_files": session_log_details
    }
    write_summary_log(overall_log)


if __name__ == "__main__":
    if CONFIG:
        main()
--- END FILE: scripts/universal_content_merger.py ---

--- START FILE: scripts/pdf_translator.py ---
# --- Importing necessary libraries ---
# --- Importowanie niezbędnych bibliotek ---
# For filesystem operations like creating paths and folders. / Do operacji na systemie plików, jak tworzenie ścieżek i folderów.
import os
# For opening and extracting text from PDF files. / Do otwierania i wyciągania tekstu z plików PDF.
import pdfplumber
# For generating unique timestamps for filenames. / Do generowania unikalnych znaczników czasu dla nazw plików.
import datetime
# For loading configuration files in YAML format. / Do wczytywania plików konfiguracycyjnych w formacie YAML.
import yaml
# For system interaction, e.g., to exit the script. / Do interakcji z systemem, np. do przerwania działania skryptu.
import sys
# For using regular expressions to fix line wrapping. / Do używania wyrażeń regularnych w celu naprawy zawijania wierszy.
import re
# For structured logging in JSON format. / Do strukturalnego logowania w formacie JSON.
import json
# For timing operations and pausing the script. / Do mierzenia czasu operacji i pauzowania skryptu.
import time
# The official Google library for interacting with the Gemini API. / Oficjalna biblioteka Google do interakcji z API Gemini.
import google.generativeai as genai
# For handling specific API errors like rate limiting. / Do obsługi specyficznych błędów API, takich jak limity zapytań.
from google.api_core import exceptions

# --- ReportLab imports for advanced PDF creation with paragraphs ---
# --- Importy ReportLab do zaawansowanego tworzenia PDF z akapitami ---
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib.enums import TA_JUSTIFY


# --- MAIN CONFIGURATION LOADING FUNCTION ---
# --- GŁÓWNA FUNKCJA ŁADUJĄCA KONFIGURACJĘ ---
def load_configuration(config_path='config.yaml'):
    """
    Loads configuration from a YAML file.
    Wczytuje konfigurację z pliku YAML.
    """
    try:
        with open(config_path, "r", encoding="utf-8") as cr:
            config = yaml.full_load(cr)

        if 'base_path' not in config:
            raise ValueError("Key 'base_path' is required.")
        if 'translator_script_config' not in config:
            raise ValueError("Section 'translator_script_config' is required.")
        if 'KEY' not in config or not config['KEY'] or config['KEY'] == "TWOJ_KLUCZ_API_GEMINI" or config[
            'KEY'] == "*****":
            raise ValueError("Gemini API Key ('KEY') is missing or is a placeholder.")

        base_path = config['base_path']
        translator_config = config['translator_script_config']

        conf = {
            "GEMINI_API_KEY": config['KEY'],
            "SOURCE_FOLDER": os.path.join(base_path, translator_config['source_folder']),
            "OUTPUT_FOLDER": os.path.join(base_path, translator_config['output_folder']),
            "LOG_FOLDER": os.path.join(base_path, translator_config.get('log_folder', 'LOGS')),
            "FONT_PATH": os.path.join(base_path, translator_config['font_path']),
            "FONT_NAME": translator_config['font_name'],
            "FONT_SIZE": translator_config.get('font_size', 10),
            "MODEL_NAME": translator_config.get('model_name', 'gemini-1.5-flash'),
            "CHUNK_SIZE_CHARS": translator_config.get('chunk_size_chars', 30000),
            "TARGET_LANGUAGES": translator_config.get('target_languages', ['English', 'Polish', 'Czech'])
        }
        print("Configuration loaded successfully.")
        print("Konfiguracja załadowana pomyślnie.")
        return conf
    except Exception as e:
        print(f"FATAL ERROR in configuration: {e}")
        print(f"BŁĄD KRYTYCZNY w konfiguracji: {e}")
        return None


# --- Initialization ---
# --- Inicjalizacja ---
CONFIG = load_configuration()
MODEL = None
if CONFIG:
    try:
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        genai.configure(api_key=CONFIG['GEMINI_API_KEY'])
        MODEL = genai.GenerativeModel(CONFIG['MODEL_NAME'], safety_settings=safety_settings)
        print("Gemini API configured successfully.")
        print("Gemini API skonfigurowane pomyślnie.")
    except Exception as e:
        CONFIG = None
    if CONFIG:
        os.makedirs(CONFIG['SOURCE_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['OUTPUT_FOLDER'], exist_ok=True)
        os.makedirs(CONFIG['LOG_FOLDER'], exist_ok=True)
        try:
            pdfmetrics.registerFont(TTFont(CONFIG['FONT_NAME'], CONFIG['FONT_PATH']))
            print(f"Font '{CONFIG['FONT_NAME']}' registered successfully.")
            print(f"Czcionka '{CONFIG['FONT_NAME']}' zarejestrowana pomyślnie.")
        except Exception as e:
            print(f"ERROR: Could not register font. Defaulting to Helvetica. Error: {e}")
            print(f"BŁĄD: Nie można zarejestrować czcionki. Używam domyślnej Helvetica. Błąd: {e}")
            CONFIG['FONT_NAME'] = "Helvetica"
else:
    print("Exiting script due to configuration errors.")
    print("Zamykanie skryptu z powodu błędów konfiguracji.")
    sys.exit(1)


# --- Core Functions ---
# --- Główne Funkcje ---

def extract_full_text_from_pdf(pdf_path):
    """
    Extracts all text from a PDF file into a single string.
    Ekstrahuje cały tekst z pliku PDF do jednego ciągu znaków.
    """
    print(f"Extracting full text from '{os.path.basename(pdf_path)}'...")
    print(f"Ekstrahuję pełny tekst z '{os.path.basename(pdf_path)}'...")
    full_text = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    full_text.append(page_text)
        return "\n\n".join(full_text)
    except Exception as e:
        print(f"ERROR: Could not read PDF file {pdf_path}: {e}")
        print(f"BŁĄD: Nie można odczytać pliku PDF {pdf_path}: {e}")
        return None


def chunk_text(text, chunk_size):
    """
    Splits a large text into smaller chunks based on a character size limit.
    Dzieli duży tekst na mniejsze kawałki na podstawie limitu znaków.
    """
    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]


def translate_text_in_chunks(text_to_translate, target_language):
    """
    Translates text, handles rate limits and overloads by retrying, and manages other safety blocks.
    Tłumaczy tekst, obsługuje limity i przeciążenia poprzez ponawianie prób i zarządza innymi blokadami.
    """
    if not text_to_translate or not text_to_translate.strip():
        return "", 0, 0, "EMPTY_INPUT"

    chunks = chunk_text(text_to_translate, CONFIG['CHUNK_SIZE_CHARS'])
    print(f"Text divided into {len(chunks)} chunk(s) for translation to {target_language}.")
    print(f"Tekst podzielony na {len(chunks)} części do tłumaczenia na {target_language}.")

    translated_parts = []
    total_input_tokens = 0
    total_output_tokens = 0
    final_status = "Success"

    base_prompt = f"You are a professional translator. Translate the following document fragment into {target_language}. Preserve the original formatting, including paragraph breaks. Return only the translated text, without any additional comments, explanations or introductions."

    for i, chunk in enumerate(chunks):
        print(f"  Translating chunk {i + 1}/{len(chunks)}...")
        print(f"  Tłumaczę część {i + 1}/{len(chunks)}...")
        prompt = f"{base_prompt}\n\nFragment to translate:\n\n{chunk}"

        max_retries = 5
        current_retry = 0
        delay = 15

        while current_retry < max_retries:
            try:
                response = MODEL.generate_content(prompt)

                if not response.parts:
                    block_reason = response.prompt_feedback.block_reason.name if response.prompt_feedback else "UNKNOWN"
                    print(
                        f"  WARNING: Chunk {i + 1} translation blocked by API. Reason: {block_reason}. Inserting original text.")
                    print(
                        f"  OSTRZEŻENIE: Tłumaczenie fragmentu {i + 1} zablokowane przez API. Powód: {block_reason}. Wstawiam oryginalny tekst.")
                    warning_msg = f"[API TRANSLATION BLOCKED (REASON: {block_reason}) - ORIGINAL TEXT INSERTED BELOW]"
                    translated_parts.append(f"\n\n--- {warning_msg} ---\n\n{chunk}\n\n")
                    final_status = "API_BLOCK"
                    break

                translated_parts.append(response.text)
                if hasattr(response, 'usage_metadata'):
                    total_input_tokens += response.usage_metadata.prompt_token_count
                    total_output_tokens += response.usage_metadata.candidates_token_count
                break

            except (exceptions.ResourceExhausted, exceptions.ServiceUnavailable, exceptions.DeadlineExceeded) as e:
                current_retry += 1
                error_type = type(e).__name__
                if current_retry >= max_retries:
                    print(f"  ERROR: Max retries exceeded for chunk. Error: {error_type}. Inserting original text.")
                    print(
                        f"  BŁĄD: Przekroczono maksymalną liczbę prób dla fragmentu. Błąd: {error_type}. Wstawiam oryginalny tekst.")
                    translated_parts.append(
                        f"\n\n[TRANSLATION FAILED AFTER RETRIES: {error_type}] - ORIGINAL TEXT INSERTED BELOW\n\n{chunk}\n\n")
                    final_status = "MAX_RETRIES_EXCEEDED"
                    break

                print(
                    f"  API temporary error ({error_type}). Retrying in {delay} seconds... (Attempt {current_retry}/{max_retries})")
                print(
                    f"  Tymczasowy błąd API ({error_type}). Ponawiam próbę za {delay} sekund... (Próba {current_retry}/{max_retries})")
                time.sleep(delay)
                delay *= 2

            except Exception as e:
                print(f"  An unexpected API error occurred: {e}. Inserting original text.")
                print(f"  Wystąpił nieoczekiwany błąd API: {e}. Wstawiam oryginalny tekst.")
                translated_parts.append(
                    f"\n\n[UNEXPECTED TRANSLATION ERROR: {e}] - ORIGINAL TEXT INSERTED BELOW\n\n{chunk}\n\n")
                final_status = "UNEXPECTED_ERROR"
                break
        time.sleep(1)

    print(f"Token Usage for {target_language}: Input={total_input_tokens}, Output={total_output_tokens}")
    print(f"Zużycie tokenów dla {target_language}: Wejście={total_input_tokens}, Wyjście={total_output_tokens}")
    return "\n\n".join(translated_parts), total_input_tokens, total_output_tokens, final_status


def reflow_text(text: str) -> str:
    """
    Intelligently joins lines for better PDF formatting.
    Inteligentnie łączy linie dla lepszego formatowania PDF.
    """
    reflowed = re.sub(r'(?<!\n)\n(?!\n)', ' ', text)
    reflowed = re.sub(r'\n{2,}', '<br/><br/>', reflowed)
    return reflowed


def save_text_to_pdf(text_content, output_pdf_path):
    """
    Saves the given text content to a PDF file using Platypus for proper text wrapping.
    Zapisuje podany tekst do pliku PDF, używając biblioteki Platypus do poprawnego zawijania tekstu.
    """
    font_name, font_size = CONFIG['FONT_NAME'], CONFIG['FONT_SIZE']
    print(f"Saving PDF to: {output_pdf_path}...")
    print(f"Zapisuję PDF do: {output_pdf_path}...")

    doc = SimpleDocTemplate(output_pdf_path, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)
    styles = getSampleStyleSheet()
    style = ParagraphStyle(name='Normal_Justified', parent=styles['Normal'], fontName=font_name, fontSize=font_size,
                           leading=font_size * 1.5, alignment=TA_JUSTIFY)

    processed_text = reflow_text(text_content)
    story = [Paragraph(processed_text, style)]

    try:
        doc.build(story)
        print(f"Successfully saved PDF: {output_pdf_path}")
        print(f"Pomyślnie zapisano PDF: {output_pdf_path}")
    except Exception as e:
        print(f"ERROR saving PDF: {e}")
        print(f"BŁĄD podczas zapisywania PDF: {e}")


# --- New Logging Function ---
# --- Nowa Funkcja Logowania ---
def write_summary_log(log_data):
    """
    Writes a JSON summary log for the entire session.
    Zapisuje podsumowujący log JSON dla całej sesji.
    """
    log_file_path = os.path.join(CONFIG['LOG_FOLDER'], f"translator_log_{log_data['session_start_iso']}.json")
    try:
        with open(log_file_path, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=4, ensure_ascii=False)
        print(f"\n--- Summary log created successfully: {log_file_path} ---")
        print(f"--- Podsumowujący log został pomyślnie utworzony: {log_file_path} ---")
    except Exception as e:
        print(f"ERROR: Could not write summary log file: {e}")
        print(f"BŁĄD: Nie można zapisać pliku z logami: {e}")


# --- Main Execution ---
# --- Główne Wykonanie ---
def main():
    """
    Main function to find, translate, and save PDFs into separate files per language.
    Główna funkcja do znajdowania, tłumaczenia i zapisywania plików PDF w osobnych plikach dla każdego języka.
    """
    script_start_time = time.time()
    session_start_iso = datetime.datetime.now().isoformat().replace(":", "-")
    session_log_details = []

    print(f"Starting PDF translation from folder: {CONFIG['SOURCE_FOLDER']}")
    print(f"Rozpoczynam tłumaczenie PDF z folderu: {CONFIG['SOURCE_FOLDER']}")

    pdf_files = sorted([f for f in os.listdir(CONFIG['SOURCE_FOLDER']) if f.lower().endswith(".pdf")])

    if not pdf_files:
        print("INFO: No PDF files found in the source folder for translation.")
        print("INFO: Brak plików PDF w folderze źródłowym do tłumaczenia.")
        return

    for pdf_file in pdf_files:
        print(f"\n--- Processing file: {pdf_file} ---")
        print(f"--- Przetwarzam plik: {pdf_file} ---")

        file_start_time = time.time()
        pdf_path = os.path.join(CONFIG['SOURCE_FOLDER'], pdf_file)

        file_log = {
            "file_name": pdf_file,
            "status": "Processing",
            "details": "",
            "translations": []
        }

        original_text = extract_full_text_from_pdf(pdf_path)

        if not original_text:
            print(f"WARNING: No text extracted from '{pdf_file}'. Skipping.")
            print(f"OSTRZEŻENIE: Nie wyekstrahowano tekstu z '{pdf_file}'. Pomijam.")
            file_log['status'] = "Skipped"
            file_log['details'] = "No text extracted from PDF."
            session_log_details.append(file_log)
            continue

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.splitext(pdf_file)[0]

        lang_suffix_map = {
            "english": "EN", "polish": "PL", "arabic": "AR", "chinese": "ZH",
            "czech": "CS", "french": "FR", "german": "DE", "hebrew": "HE",
            "japanese": "JA", "persian": "FA", "russian": "RU", "spanish": "ES",
            "ukrainian": "UK",
        }

        any_translation_failed = False

        for lang in CONFIG.get('TARGET_LANGUAGES', ['English', 'Polish']):
            print(f"\n--- Starting translation for {lang} ---")
            print(f"--- Rozpoczynam tłumaczenie na {lang} ---")

            lang_start_time = time.time()
            lang_log = {"language": lang}

            translated_text, input_tokens, output_tokens, status = translate_text_in_chunks(original_text, lang)

            lang_log["status"] = status
            lang_log["token_usage"] = {"input": input_tokens, "output": output_tokens,
                                       "total": input_tokens + output_tokens}

            if translated_text and status == "Success":
                lang_lower = lang.lower()
                lang_suffix = lang_suffix_map.get(lang_lower, lang_lower[:2].upper())
                output_path = os.path.join(CONFIG['OUTPUT_FOLDER'], f"{base_name}_{timestamp}_{lang_suffix}.pdf")
                save_text_to_pdf(translated_text, output_path)
                lang_log["output_file"] = output_path
            else:
                print(f"WARNING: Translation for {lang} resulted in empty or problematic text. No file will be saved.")
                print(
                    f"OSTRZEŻENIE: Tłumaczenie na {lang} zwróciło pusty lub problematyczny tekst. Plik nie zostanie zapisany.")
                lang_log["output_file"] = None
                if status != "API_BLOCK":  # Don't mark as failure if it's a known non-critical issue
                    any_translation_failed = True

            lang_log["processing_time_seconds"] = round(time.time() - lang_start_time, 2)
            file_log["translations"].append(lang_log)

            sleep_duration = 20
            print(f"--- Finished {lang}. Waiting for {sleep_duration} seconds before next language... ---")
            print(f"--- Ukończono {lang}. Czekam {sleep_duration} sekund przed kolejnym językiem... ---")
            time.sleep(sleep_duration)

        file_log["status"] = "Completed_with_errors" if any_translation_failed else "Completed_successfully"
        file_log["total_processing_time_seconds"] = round(time.time() - file_start_time, 2)
        session_log_details.append(file_log)

    print("\n--- Finished translation process for all files. ---")
    print("\n--- Zakończono proces tłumaczenia dla wszystkich plików. ---")

    script_end_time = time.time()
    overall_log = {
        "session_start_iso": session_start_iso,
        "total_duration_seconds": round(script_end_time - script_start_time, 2),
        "total_files_processed": len(pdf_files),
        "model_used": CONFIG['MODEL_NAME'],
        "processed_files": session_log_details
    }
    write_summary_log(overall_log)


if __name__ == "__main__":
    if CONFIG:
        main()
--- END FILE: scripts/pdf_translator.py ---

